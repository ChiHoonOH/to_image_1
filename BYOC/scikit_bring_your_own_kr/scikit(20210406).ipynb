{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BYOC scikit-learn(scikit-learn 알고리즘 커스텀 컨테이너 빌드하기)\n",
    "\n",
    "***Note: 본 핸즈온은 SageMaker SDK V2에 대응하도록 코드를 수정했습니다. 만약 SDK V1용 코드가 필요하다면 아래 링크를 참조해 주십시오.***\n",
    "\n",
    "소스 : https://github.com/awslabs/amazon-sagemaker-examples/tree/master/advanced_functionality/scikit_bring_your_own\n",
    "\n",
    "Amazon SageMaker에서는 여러분들의 알고리즘을 SageMaker 환경에서 학습과 추론을 할수 있도록 패키징하는 기능을 제공합니다. 본 노트북은 SageMaker 학습과 추론용으로 어떻게 도커 컨테이너 이미지를 만들게 되는지 그 과정을 다룹니다.\n",
    "\n",
    "알고리즘을 컨테이너로 패키징함으로써, 프로그래밍 언어나, 환경, 프레임워크와 의존관계에 관계엾이, 사실상 어떤 코드든 SageMaker환경에서 실행할 수 있습니다. \n",
    "\n",
    "_**Note:**_ 본 예제는 sciikit learn알고리즘을 커스텀 컨테이너로 패키징하는 방법을 다루지만, SageMaker는 사전 빌드된 [scikit container](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/scikit_learn_iris/Scikit-learn%20Estimator%20Example%20With%20Batch%20Transform.ipynb)를 제공합니다. scikit 알고리즘이 필요한 모든 경우에 이 컨테이너를 사용할 것을 권장합니다. 본 예제는 커스텀 컨테이너를 직접 빌드하는 사례로 참고해 주십시오. \n",
    "\n",
    "설명없이 코드로 바로 시작하시려면 __도커파일 (코드 시작)__ 섹션으로 바로 이동하십시오.  \n",
    "\n",
    "## 언제 커스텀 알고리즘 컨테이너를 사용해야 하나요?\n",
    "\n",
    "여러분의 코드를 SageMaker에서 구동하기 위하여 반드시 컨테이너를 직접 만들어야 하는 것은 아닙니다. 만약 여러분이 사용하는 프레임웤이 Apach MXNet이나 Tensorflow 등일 경우 SageMaker는 해당 프레임워크를 직접 지원하기 때문에 여러분은 알고리즘을 구현하는 파이썬 코드만 제공하고 이를 프레임워크 SDK의 entry point에 전달하여 활용할 수 있습니다. SageMaker에서 지원되는 프레임워크는 정기적으로 추가되고 있고, SageMaker에서 지원하는 범용 머신러닝 환경 리스트를 통해 여러분이 작성하시는 알고리즘의 환경이 SageMaker에서 지원되는 지를 확인할 수 있습니다. \n",
    "\n",
    "단, 여러분의 환경이나 프레임워크를 지원하는 SDK가 있다고 하더라도 커스텀 컨테이너를 직접 빌드하는 것이 보다 효과적일 경우도 있습니다. 여러분의 알고리즘 코드가 매우 복잡하거나 추가로 다른 프레임웤를 필요로 하는 경우에는 컨테이너를 직접 빌드하는 것이 적절한 선택일 수도 있습니다. 이런 경우에 해당하는 몇가지 사례는 다음과 같습니다. \n",
    "\n",
    "1. 프레임워크의 특정 버전이 지원되지 않는 경우\n",
    "2. 환경에 의존라이브러리들을 추가로 설치하고 설정하는 경우\n",
    "3. 기본 환경에서 제공되지 않는 학습/배포 솔루션을 사용하는 경우\n",
    "\n",
    "커스텀 컨테이너를 이용하면 SageMaker에서 사전 제공하지 않는 환경일 경우에도 SageMaker기반으로 동작하도록 할 수 있습니다. 본 예제에서 그 과정을 살펴보겠습니다. \n",
    "\n",
    "## 권한설정\n",
    "\n",
    "본 노트북은 `SageMakerFullAccess`권한에 추가로 Amazon ECR에 접근하기 위한 권한이 필요합니다. 권한을 추가하는 가장 간단한 방법은 관리형 정책인 `AmazonEC2ContainerRegistryFullAccess`를 노트북 인스턴스가 사용중인 역할(role)에 추가하는 것입니다. 이를 위해 노트북 인스턴스를 재시작할 필요는 없으며 수정 즉시 새로운 권한이 할당 될 것입니다. \n",
    "\n",
    "## 샘플 시나리오\n",
    "\n",
    "본 샘플에서는 [scikit-learn][] 머신러닝 패키지의 [의사결정트리][] 알고리즘을 이용하는 간단한 파이썬 예제를 보여줍니다. 샘플코드는 매우 간단합니다. 대신 SageMaker에서 구현을 위해 어떤 구조를 사용하고 코드의 어떤부분이 수정되어야 하는지에 주로 집중할 것입니다. \n",
    "\n",
    "본 예제의 방식은 어떤 프로그래밍언어나 환경에서도 동일합니다. 여러분의 환경에 맞는 다른 HTTP 추론 요청을 처리할 수 있는 도구를 선택하여 구현할 수 있습니다.\n",
    "\n",
    "본 예제에서는 학습과 추론 실행을 단일 이미지로 사용할 것입니다. 하나의 이미지로 학습과 추론을 실행하는 경우 하나의 이미지만 관리하면 되므로 관리절차가 단순해 집니다. 하지만 실제 요구사항에 따라 이 두 환경의 이미지가 분리될 수도 있을 것입니다. 이 경우 Dockerfile을 분리하고 두 개의 이미지를 운영하게 됩니다. 이미지의 분리와 통합은 실제 환경 요구사항과 개발 및 관리 편의성을 고려하여 결정합니다. \n",
    "\n",
    "그리고 SageMaker에서 학습과 추론을 모두 실행하지 않고 이 중 한가지 방식만 이용할 경우에는 해당 기능의 이미지만 빌드하면 됩니다.\n",
    "\n",
    "[scikit-learn]: http://scikit-learn.org/stable/\n",
    "[의사결정트리]: http://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "본 예제는 컨테이너를 __빌드__하는 부분과 __활용__하는 부분의 두 파트로 나누어져 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: 알고리즘을 SageMaker 환경으로 패키징하고 업로드하기 \n",
    "\n",
    "### 도커 개요\n",
    "\n",
    "만약 여러분이 이미 도커 환경이 친숙하다면 이 단계는 건너뛰고 다음 섹션으로 이동하십시오.\n",
    "\n",
    "많은 데이터 사이언티스트들에게 도커 컨테이너는 새로운 기술입니다. 하지만 도커는 여러분의 소프트웨어를 패키징하여 배포하는 매우 간편한 방법이며 그리 어렵지 않습니다. \n",
    "\n",
    "도커는 임의의 코드를 스스로 실행환경을 포함하는 __이미지__로 패키징하는 간단한 방법을 제공합니다. 이미지가 생성되고 나면, 도커 환경에서 이 이미지를 __컨테이너__로 실행하게 됩니다. 컨테이너를 실행하는 것은 컨테이너가 프로그램이 실행될 실행환경을 스스로 생성한다는 것을 제외하면 일반적으로 컴퓨터 머신에서 프로그램을 실행하는 것과 다르지 않습니다. 컨테이너는 호스트 환경에서 다른 컴퓨팅 환경과 격리됩니다. 이것은 이 컨테이너가 어디에 실행되는지에 관계없이 독자적인 실행방식을 구성할 수 있게 만들어 줍니다.\n",
    "\n",
    "도커는 다음과 같은 이유로 conda나 virtualenv와 같은 환경관리에 비해 매우 강력합니다. \n",
    "- 도커 환경은 프로그래밍 언에에 독립적입니다.\n",
    "- 초기 실행명령과 환경변수까지 전체 운영환경을 포괄합니다.\n",
    "\n",
    "도커 컨테이너는 가상머신과 유사하지만 보다 경령화되어 있습니다. 예를 들어, 컨테이너에서 실행되는 프로그램은 1초 이내에 시작될 수 있고 물리 또는 가상 서버 인스턴스에서 동시에 실행될 수 있습니다. \n",
    "\n",
    "도커는 `Dockerfile`이라는 간단한 파일을 사용하여 이미지가 구성되는 방식을 정의합니다. 그 사례는 아래에 제공됩니다. 여러분은 여러분이 만들거나 또는 다른 사람이 만든 도커 이미지를 기반으로 새로운 도커 이미지를 만들 수 있습니다. 이런 방식은 이미지의 생성을 매우 단순화시켜줍니다.\n",
    "\n",
    "도커는 이런 유연함과 함께 잘 정리된 컨테이너 설정방식을 제공하여 프로그래밍과 개발 커뮤니테에서 열광적인 환영을 받고 있으며, 최근 [Amazon ECS]나 [Amazon EKS]와 같은 많은 서비스가 이 기술을 기반으로 구현되고 제공되고 있습니다. \n",
    "\n",
    "Amazon SageMaker 또한 사용자가 임의의 알고리즘을 학습하고 배포할 때 이 도커를 이용합니다. \n",
    "\n",
    "Amazon SageMaker 에서 도커 컨테이너는 학습을 위한 방식과, 학습과는 조금 다른 추론 호스팅의 방식으로 호출(invoke) 됩니다. 다음 섹션에서 SageMaker 환경에서 컨테이너를 어떻게 빌드하는지에 대해 설명합니다. \n",
    "\n",
    "도커와 관련한 보다 자세한 내용은 아래 링크를 참고하십시오. \n",
    "\n",
    "* [Docker home page](http://www.docker.com)\n",
    "* [Getting started with Docker](https://docs.docker.com/get-started/)\n",
    "* [Dockerfile reference](https://docs.docker.com/engine/reference/builder/)\n",
    "* [`docker run` reference](https://docs.docker.com/engine/reference/run/)\n",
    "\n",
    "[Amazon ECS]: https://aws.amazon.com/ecs/\n",
    "[Amazon EKS]: https://aws.amazon.com/eks/\n",
    "\n",
    "### Amazon SageMaker 에서 도커 컨테이너 실행 방식 \n",
    "\n",
    "SageMaker에서 학습과 호스팅에 동일한 이미지를 사용할 수 있으며, 컨테이너를 실행시 `train` 또는 `serve`라는 매개변수(argument)를 이용하여 컨테이너를 실행합니다. 컨테이너가 이 매개변수를 처리하는 방식은 컨테이너 구성에 따라 달라집니다.\n",
    "\n",
    "* 본 샘플에서는 도커파일(Dokerfile)에서 `ENTRYPOINT`를 사용하지 않습니다. 대신 학습시점에는 [`train`](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html) 명령을 서빙(호스팅)시점에는 [`serve`](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html) 명령을 이용하여 도커를 실행합니다.\n",
    "* 만약 도커파일에서 `ENTRYPOINT`를 이용하여 프로그램을 명시하게 되면 도커 실행시 해당프로그램이 실행되며 `train` 또는 `serve`가 첫번째 매개변수로 전달될 것입니다. 프로그램은 이 매개변수에 따라 무슨 동작을 해야할 지를 판단할 수 있습니다. \n",
    "* 만약 학습과 호스팅 컨테이너를 분리하는 경우 (또는 둘 장 하나의 방식만 활용하는 경우) 도커파일에 `ENTRYPOINT`에 프로그램을 정의할 수 있고, 이 때 전달되는 첫번째 매개변수는 무시하거나 또는 검증용으로 사용할 수 있습니다. \n",
    "\n",
    "\n",
    "#### 학습(training)용으로 커스텀 컨테이너 이용하기 \n",
    "\n",
    "SageMaker에서 학습이 실행될 때 여러분의 `train` 스크립트가 실행됩니다. 일반적인 파이썬 프로그램이 실행되는 것과 마찬가지 방식이며, `/opt/ml` 디렉토리의 몇가지 파일들이 활용될 수 있습니다.\n",
    "\n",
    "    /opt/ml\n",
    "    |-- input\n",
    "    |   |-- config\n",
    "    |   |   |-- hyperparameters.json\n",
    "    |   |   `-- resourceConfig.json\n",
    "    |   `-- data\n",
    "    |       `-- <channel_name>\n",
    "    |           `-- <input data>\n",
    "    |-- model\n",
    "    |   `-- <model files>\n",
    "    `-- output\n",
    "        `-- failure\n",
    "\n",
    "##### 데이터 입력\n",
    "\n",
    "* `/opt/ml/input/config` - 프로그램이 실행되는 방식을 관리할 수 있는 정보가 포함됩니다. `hyperparameters.json` 은 하이퍼파라미터 이름과 값을 가지는 JSON 형식의 딕셔너리입니다. 값은 string 형태로 전달되며 필요시 타입을 변환하여 사용합니다. `resourceConfig.json` 은 분산학습에서 네트워크 레이아웃을 알려주는 JSON형식의 파일입니다. \n",
    "\n",
    "* `/opt/ml/input/data/<channel_name>/` - (파일 모드일 경우) 채널에 대한 입력데이터가 저장됩니다. 채널은 CreateTrainingJob(또는 fit)을 호출할 때 생성되며 알고리즘 코드에서 동일하게 사용해야 합니다. 알고리즘에서 사용할 파일들이 S3로부터 지정한 채널로 복사되며 S3 키의 트리 구조를 유지합니다. \n",
    "\n",
    "* `/opt/ml/input/data/<channel_name>_<epoch_number>` (파이프 모드일 경우) 실행되는 epoch을 위한 파이프입니다. epoch은 0에서부터 이 채널을 읽을때마다 증가합니다. epoch숫자에 제한은 없으며 다음 epoch을 실행하기 전에 pipe를 close 해야 합니다. \n",
    "\n",
    "\n",
    "##### 학습결과 출력\n",
    "\n",
    "* `/opt/ml/model/` - 알고리즘이 생성하는 모델이 저장되는 디렉토리입니다. 모델의 형식은 여러분이 지정하는 방식에 따라 달라지며, 단일 파일일 수도 있고 트리구조를 가지는 디렉토리 전체일 수도 있습니다. 모델 파일은 `DescribeTrainingJob` 호출 결과로 리턴되는 지정된 S3 위치에 사용가능하도록 export 됩니다. \n",
    "\n",
    "* `/opt/ml/output` - 작업이 실패할 때 `failure` 파일을 저장하는 디렉토리입니다. 파일의 내용은 `DescribeTrainingJob`호출시 `FailureReason` 필드의 값으로 리턴됩니다. 작업이 성공적으로 종료될 경우 이 파일은 필요가 없으므로 무시됩니다. \n",
    "\n",
    "#### 호스팅(추론)용으로 컨테이너 이용하기\n",
    "\n",
    "추론 호스팅은 HTTP를 통해 들어오는 추론 요청(request)에 응답해야 하므로 학습과는 다른 모델을 가집니다. 본 사례에서는 추론 처리를 위한 일반적인 권장 파이썬 서빙 스택을 이용할 것입니다.\n",
    "\n",
    "![Request serving stack](stack.png)\n",
    "\n",
    "대부분의 경우에는 본 예제에 샘플로 구현된 스택을 그대로 사용하실 수 있을 것입니다. \n",
    "\n",
    "Amazon SageMaker기반 추론을 위해 컨테이너 내부에서 다음 두가지 URL을 사용합니다. \n",
    "\n",
    "* `/ping` - 인프라로부터 `GET` 요청을 받아서 처리합니다. 컨테이너가 정상적으로 동작하고 요청을 받을 수 있는 경우 200을 리턴합니다.\n",
    "* `/invocations` - 추론 클라이언트로부터 `POST`요청을 받아 처리합니다. 요청과 응답의 형식은 알고리즘에 따라 달라집니다. 클라이언트가 `ContentType`과 `Accept` 헤더를 지정한 경우 함께 전달됩니다.\n",
    "\n",
    "추론 컨테이너의 모델 파일 위치는 학습에서 생성한 모델을 저장할 때 사용한 위치와 동일합니다. \n",
    "\n",
    "    /opt/ml\n",
    "    `-- model\n",
    "        `-- <model files>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parts of the sample container\n",
    "\n",
    "본 예제의 `container` 디렉토리에 샘플 알고리즘을 SageMaker환경으로 패키징하는 모든 파일들이 저장되어 있습니다.\n",
    "\n",
    "    .\n",
    "    |-- Dockerfile\n",
    "    |-- build_and_push.sh\n",
    "    `-- decision_trees\n",
    "        |-- nginx.conf\n",
    "        |-- predictor.py\n",
    "        |-- serve\n",
    "        |-- train\n",
    "        `-- wsgi.py\n",
    "\n",
    "이들 파일을 차례로 살펴보면:\n",
    "\n",
    "* __`Dockerfile`__ - 도커 컨테이너 이미지를 빌드하는 방법이 정의됩니다. 다음 섹션에서 다시 설명합니다. \n",
    "* __`build_and_push.sh`__ - Dockerfile을 이용하여 컨테이너 이미지를 빌드하고 ECR로 push하는 스크립트입니다. 본 노트북에서 이 쉘을 직접 실행할 것입니다. 이후 여러분의 알고리즘에 적용할 경우에도 이 파일을 그대로 사용할 수 있습니다. \n",
    "* __`decision_trees`__ - 컨테이너 내부로 복제될 파일들이 저장되어 있습니다. \n",
    "* __`local_test`__ - SageMaker 노트북 등 로컬 환경에서 도커를 구동하고 테스트하는 방법을 보여줍니다. 이 방법을 이용하면 SageMaker 컨테이너 환경을 이용하기 전에 작은 데이터셋으로 빠르게 실행하여 결함을 찾을 수 있습니다. 본 예제에서 사용방법을 다룰 것입니다. \n",
    "\n",
    "본 예제에서 우리는 5개의 파일을 컨테이너로 복제할 것입니다. 실제로는 여러분의 유즈케이스에 따라 이정도의 파일이 충분할 수도 있고 또는 더 많은 파일이 필요할 수도 있습니다. 하지만 이 5개의 파일이 커스텀 파이썬 컨테이너의 표준 구조가 됩니다. 예제코드와 다른 프로그래밍 언어나 도구(toolkit)를 사용할 경우에는 다른 구성을 가질 것입니다. \n",
    "\n",
    "본 예제에서 컨테이너에 복제될 파일은 다음과 같습니다. (`cifar10`디렉토리 내부의 파일들)\n",
    "\n",
    "* __`cifar10.py`__ - 알고리즘의 실행을 구현하는 프로그램 코드입니다. \n",
    "* __`resnet_model.py`__ - Resnet 모델을 정의하는 코드입니다. (`cifar10.py`에서 사용합니다.)\n",
    "\n",
    "\n",
    "* __`nginx.conf`__ - nginx front-end를 구성하는 설정 파일입니다. 일반적으로 제공되는 파일을 그대로 사용가능합니다.\n",
    "* __`predictor.py`__ - Flask 웹서버를 로직을 구현하는 프로그램입니다. 실제 운영환경에 여러분의 애플리케이션을 적용할 때에는 이 부분을 커스터마아징하게 될 것입니다. 본 예제의 로직은 복잡하지 않기 때문에 하나의 파일로 구현하지만, 실제로는 커스텀로직의 내용에 따라 여러 파일로 분리될 수도 있을 것입니다.\n",
    "* __`serve`__ - 컨테이너가 추론 호스팅을 할 때 실행되는 프로그램입니다. `predictor.py`에 구현된 Flask 웹서버 인스턴스를 복수로 실행하는 gunicorn 서버를 구동합니다. 일반적으로 본 예제에서 제공되는 파일을 그대로 사용가능합니다. \n",
    "* __`train`__ - 컨테이너가 학습을 진행할 때 실행되는 프로그램입니다. 학습 알고리즘을 구현하기 위해 이 부분을 수정할 것입니다. \n",
    "* __`wsgi.py`__ - Flask 애플리케이션을 구동하기 위한 간단한 wrapper입니다. 일반적으로 본 예제에서 제공된 파일을 그대로 사용가능합니다.\n",
    "\n",
    "\n",
    "요약하면, 이후 여러분의 실제 애플리케이션에 여러분의 알고리즘 실행코드를 적용할 때에는 해당 코드와 함께 `train`과 `predictor.py` 부분을 변경하게 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 도커파일 (코드 시작)\n",
    "\n",
    "Dockerfile은 빌드할 이미지를 정의합니다. 실행할 시스템의 운영체제와 환경을 완전히 정의하는 것으로 생각해도 좋습니다. 하지만 실제로 도커 컨테이너의 실행은 운영체제를 모두 준비하는 것에 비해 매우 경량화되어 있으며 기초 동작은 호스트머신의 Linux를 활용합니다. \n",
    "\n",
    "파이선 데이터사이언스 스택을 준비하기 위해 표준 Ubunto 이미지로 부터 시작하하여 기본 도구와 scikit-learn을 설치하겠습니다. 그리고 이 환경에서 실행될 사용자 알고리즘 코드를 추가하겠습니다. \n",
    "\n",
    "아래 코드를 이용하여 Dockerfile을 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker\n",
    "\n",
    "#!pwd\n",
    "\n",
    "#! ls -al /home/ec2-user/\n",
    "\n",
    "#! cat /home/ec2-user/.bash_profile\n",
    "\n",
    "#! cat /home/ec2-user/.bashrc\n",
    "\n",
    "#! ls /opt/ml/metadata\n",
    "\n",
    "#! ls container/\n",
    "\n",
    "#! cat container/ReadMe.md\n",
    "\n",
    "#! cat /opt/ml/metadata/resource-metadata.json\n",
    "\n",
    "#!cat container/Dockerfile-random-forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨테이너 빌드 및 등록\n",
    "\n",
    "다음 쉘스크립트는 `docker build` 명령을 이용하여 컨테이너를 빌드하고 `docker push`명령을 이용하여 ECR에 빌드한 이미지를 push하는 방법을 보여줍니다. 해당 코드는 `container/build-and-push.sh`의 내용과 동일하며 `decision_trees_sample`라는 이름으로 이미지를 빌드하고 push 하고자 할 때 `build-and-push.sh decision_trees_sample`와 같은 형식으로 실행하면 됩니다.\n",
    "\n",
    "아래 코드는 여러분의 어카운트의 디폴트 리전 (또는 SageMaker 노트북 인스턴스를 사용중인 경우 노트북이 생성된 리전)에서 ECR 레포지토리를 찾고, 만약 레포지토리가 없다면 이를 생성할 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decision-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%sh\n",
    "\n",
    "# # The name of our algorithm\n",
    "# algorithm_name=sagemaker-decision-trees # repository name\n",
    "# folder_name=decision_trees\n",
    "# env_param=\"FOLDER_DIR=${folder_name}\"\n",
    "# cd container\n",
    "\n",
    "# chmod +x decision_trees/train\n",
    "# chmod +x decision_trees/serve\n",
    "\n",
    "# account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# # Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "# region=$(aws configure get region)\n",
    "# #region=${region:-us-west-2}\n",
    "\n",
    "# fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# # If the repository doesn't exist in ECR, create it.\n",
    "# aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "# if [ $? -ne 0 ]\n",
    "# then\n",
    "#     aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "# fi\n",
    "\n",
    "# # Get the login command from ECR and execute it directly\n",
    "# aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# # Build the docker image locally with the image name and then push it to ECR\n",
    "# # with the full name.\n",
    "\n",
    "# docker build  --build-arg ${env_param} -t ${algorithm_name} .\n",
    "# docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "\n",
    "# docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other model=sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLDER_DIR=sagemaker-random-forest\n",
      "533821149268.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-random-forest:latest\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  219.1kB\r",
      "\r\n",
      "Step 1/13 : FROM ubuntu:18.04\n",
      " ---> 3339fde08fc3\n",
      "Step 2/13 : MAINTAINER Amazon AI <sage-learner@amazon.com>\n",
      " ---> Using cache\n",
      " ---> 1302b3fdc513\n",
      "Step 3/13 : ARG FOLDER_DIR\n",
      " ---> Using cache\n",
      " ---> 2a235613cb63\n",
      "Step 4/13 : RUN apt-get -y update && apt-get install -y --no-install-recommends          wget          python3-pip          python3-setuptools          nginx          ca-certificates          git     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Running in 318dc59a858f\n",
      "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic InRelease [242 kB]\n",
      "Get:3 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2045 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages [1344 kB]\n",
      "Get:7 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [348 kB]\n",
      "Get:8 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [24.5 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1402 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2172 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [31.4 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2476 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [378 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [11.3 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [11.4 kB]\n",
      "Fetched 22.3 MB in 6s (3767 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  fontconfig-config fonts-dejavu-core git-man iproute2 libasn1-8-heimdal\n",
      "  libbsd0 libcurl3-gnutls libelf1 liberror-perl libexpat1 libfontconfig1\n",
      "  libfreetype6 libgd3 libgdbm-compat4 libgdbm5 libgeoip1 libgssapi-krb5-2\n",
      "  libgssapi3-heimdal libhcrypto4-heimdal libheimbase1-heimdal\n",
      "  libheimntlm0-heimdal libhx509-5-heimdal libicu60 libjbig0 libjpeg-turbo8\n",
      "  libjpeg8 libk5crypto3 libkeyutils1 libkrb5-26-heimdal libkrb5-3\n",
      "  libkrb5support0 libldap-2.4-2 libldap-common libmnl0 libmpdec2 libnghttp2-14\n",
      "  libnginx-mod-http-geoip libnginx-mod-http-image-filter\n",
      "  libnginx-mod-http-xslt-filter libnginx-mod-mail libnginx-mod-stream\n",
      "  libperl5.26 libpng16-16 libpsl5 libpython3-stdlib libpython3.6-minimal\n",
      "  libpython3.6-stdlib libreadline7 libroken18-heimdal librtmp1 libsasl2-2\n",
      "  libsasl2-modules-db libsqlite3-0 libssl1.1 libtiff5 libwebp6\n",
      "  libwind0-heimdal libx11-6 libx11-data libxau6 libxcb1 libxdmcp6 libxml2\n",
      "  libxpm4 libxslt1.1 mime-support multiarch-support nginx-common nginx-core\n",
      "  openssl perl perl-modules-5.26 python-pip-whl python3 python3-distutils\n",
      "  python3-lib2to3 python3-minimal python3-pkg-resources python3.6\n",
      "  python3.6-minimal readline-common ucf\n",
      "Suggested packages:\n",
      "  gettext-base git-daemon-run | git-daemon-sysvinit git-doc git-el git-email\n",
      "  git-gui gitk gitweb git-cvs git-mediawiki git-svn iproute2-doc libgd-tools\n",
      "  gdbm-l10n geoip-bin krb5-doc krb5-user fcgiwrap nginx-doc ssl-cert perl-doc\n",
      "  libterm-readline-gnu-perl | libterm-readline-perl-perl make python3-doc\n",
      "  python3-tk python3-venv python-setuptools-doc python3.6-venv python3.6-doc\n",
      "  binutils binfmt-support readline-doc\n",
      "Recommended packages:\n",
      "  patch less ssh-client libatm1 libxtables12 geoip-database krb5-locales\n",
      "  publicsuffix libsasl2-modules file xz-utils netbase build-essential\n",
      "  python3-dev python3-wheel\n",
      "The following NEW packages will be installed:\n",
      "  ca-certificates fontconfig-config fonts-dejavu-core git git-man iproute2\n",
      "  libasn1-8-heimdal libbsd0 libcurl3-gnutls libelf1 liberror-perl libexpat1\n",
      "  libfontconfig1 libfreetype6 libgd3 libgdbm-compat4 libgdbm5 libgeoip1\n",
      "  libgssapi-krb5-2 libgssapi3-heimdal libhcrypto4-heimdal libheimbase1-heimdal\n",
      "  libheimntlm0-heimdal libhx509-5-heimdal libicu60 libjbig0 libjpeg-turbo8\n",
      "  libjpeg8 libk5crypto3 libkeyutils1 libkrb5-26-heimdal libkrb5-3\n",
      "  libkrb5support0 libldap-2.4-2 libldap-common libmnl0 libmpdec2 libnghttp2-14\n",
      "  libnginx-mod-http-geoip libnginx-mod-http-image-filter\n",
      "  libnginx-mod-http-xslt-filter libnginx-mod-mail libnginx-mod-stream\n",
      "  libperl5.26 libpng16-16 libpsl5 libpython3-stdlib libpython3.6-minimal\n",
      "  libpython3.6-stdlib libreadline7 libroken18-heimdal librtmp1 libsasl2-2\n",
      "  libsasl2-modules-db libsqlite3-0 libssl1.1 libtiff5 libwebp6\n",
      "  libwind0-heimdal libx11-6 libx11-data libxau6 libxcb1 libxdmcp6 libxml2\n",
      "  libxpm4 libxslt1.1 mime-support multiarch-support nginx nginx-common\n",
      "  nginx-core openssl perl perl-modules-5.26 python-pip-whl python3\n",
      "  python3-distutils python3-lib2to3 python3-minimal python3-pip\n",
      "  python3-pkg-resources python3-setuptools python3.6 python3.6-minimal\n",
      "  readline-common ucf wget\n",
      "0 upgraded, 88 newly installed, 0 to remove and 1 not upgraded.\n",
      "Need to get 36.5 MB of archives.\n",
      "After this operation, 171 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libssl1.1 amd64 1.1.1-1ubuntu2.1~18.04.9 [1301 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython3.6-minimal amd64 3.6.9-1~18.04ubuntu1.4 [534 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libexpat1 amd64 2.2.5-3ubuntu0.2 [80.5 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3.6-minimal amd64 3.6.9-1~18.04ubuntu1.4 [1610 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-minimal amd64 3.6.7-1~18.04 [23.7 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 mime-support all 3.60ubuntu1 [30.1 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmpdec2 amd64 2.4.2-1ubuntu1 [84.1 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 readline-common all 7.0-3 [52.9 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libreadline7 amd64 7.0-3 [124 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsqlite3-0 amd64 3.22.0-1ubuntu0.4 [499 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython3.6-stdlib amd64 3.6.9-1~18.04ubuntu1.4 [1712 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3.6 amd64 3.6.9-1~18.04ubuntu1.4 [203 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython3-stdlib amd64 3.6.7-1~18.04 [7240 B]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3 amd64 3.6.7-1~18.04 [47.2 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 multiarch-support amd64 2.27-3ubuntu1.4 [6944 B]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libjpeg-turbo8 amd64 1.5.2-0ubuntu5.18.04.4 [110 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 perl-modules-5.26 all 5.26.1-6ubuntu0.5 [2762 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgdbm5 amd64 1.14.1-6 [26.0 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgdbm-compat4 amd64 1.14.1-6 [6084 B]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libperl5.26 amd64 5.26.1-6ubuntu0.5 [3534 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 perl amd64 5.26.1-6ubuntu0.5 [201 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 openssl amd64 1.1.1-1ubuntu2.1~18.04.9 [614 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ca-certificates all 20210119~18.04.1 [147 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libelf1 amd64 0.170-0.4ubuntu0.1 [44.8 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmnl0 amd64 1.0.4-2 [12.3 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 iproute2 amd64 4.15.0-2ubuntu1.3 [721 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libbsd0 amd64 0.8.7-1ubuntu0.1 [41.6 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libicu60 amd64 60.2-3ubuntu3.1 [8054 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxml2 amd64 2.9.4+dfsg1-6.1ubuntu1.3 [663 kB]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu bionic/main amd64 ucf all 3.0038 [50.5 kB]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgeoip1 amd64 1.6.12-1 [71.8 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkrb5support0 amd64 1.16-2ubuntu0.2 [30.8 kB]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libk5crypto3 amd64 1.16-2ubuntu0.2 [85.5 kB]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu bionic/main amd64 libkeyutils1 amd64 1.5.9-9.2ubuntu2 [8720 B]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkrb5-3 amd64 1.16-2ubuntu0.2 [279 kB]\n",
      "Get:36 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgssapi-krb5-2 amd64 1.16-2ubuntu0.2 [122 kB]\n",
      "Get:37 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpng16-16 amd64 1.6.34-1ubuntu0.18.04.2 [176 kB]\n",
      "Get:38 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpsl5 amd64 0.19.1-5build1 [41.8 kB]\n",
      "Get:39 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxau6 amd64 1:1.0.8-1ubuntu1 [7556 B]\n",
      "Get:40 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxdmcp6 amd64 1:1.1.2-3 [10.7 kB]\n",
      "Get:41 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb1 amd64 1.13-2~ubuntu18.04 [45.5 kB]\n",
      "Get:42 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libx11-data all 2:1.6.4-3ubuntu0.3 [114 kB]\n",
      "Get:43 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libx11-6 amd64 2:1.6.4-3ubuntu0.3 [571 kB]\n",
      "Get:44 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 wget amd64 1.19.4-1ubuntu2.2 [316 kB]\n",
      "Get:45 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1041 kB]\n",
      "Get:46 http://archive.ubuntu.com/ubuntu bionic/main amd64 fontconfig-config all 2.12.6-0ubuntu2 [55.8 kB]\n",
      "Get:47 http://archive.ubuntu.com/ubuntu bionic/main amd64 libroken18-heimdal amd64 7.5.0+dfsg-1 [41.3 kB]\n",
      "Get:48 http://archive.ubuntu.com/ubuntu bionic/main amd64 libasn1-8-heimdal amd64 7.5.0+dfsg-1 [175 kB]\n",
      "Get:49 http://archive.ubuntu.com/ubuntu bionic/main amd64 libheimbase1-heimdal amd64 7.5.0+dfsg-1 [29.3 kB]\n",
      "Get:50 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhcrypto4-heimdal amd64 7.5.0+dfsg-1 [85.9 kB]\n",
      "Get:51 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwind0-heimdal amd64 7.5.0+dfsg-1 [47.8 kB]\n",
      "Get:52 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhx509-5-heimdal amd64 7.5.0+dfsg-1 [107 kB]\n",
      "Get:53 http://archive.ubuntu.com/ubuntu bionic/main amd64 libkrb5-26-heimdal amd64 7.5.0+dfsg-1 [206 kB]\n",
      "Get:54 http://archive.ubuntu.com/ubuntu bionic/main amd64 libheimntlm0-heimdal amd64 7.5.0+dfsg-1 [14.8 kB]\n",
      "Get:55 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgssapi3-heimdal amd64 7.5.0+dfsg-1 [96.5 kB]\n",
      "Get:56 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsasl2-modules-db amd64 2.1.27~101-g0780600+dfsg-3ubuntu2.3 [15.0 kB]\n",
      "Get:57 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsasl2-2 amd64 2.1.27~101-g0780600+dfsg-3ubuntu2.3 [49.2 kB]\n",
      "Get:58 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libldap-common all 2.4.45+dfsg-1ubuntu1.10 [15.8 kB]\n",
      "Get:59 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libldap-2.4-2 amd64 2.4.45+dfsg-1ubuntu1.10 [154 kB]\n",
      "Get:60 http://archive.ubuntu.com/ubuntu bionic/main amd64 libnghttp2-14 amd64 1.30.0-1ubuntu1 [77.8 kB]\n",
      "Get:61 http://archive.ubuntu.com/ubuntu bionic/main amd64 librtmp1 amd64 2.4+20151223.gitfa8646d.1-1 [54.2 kB]\n",
      "Get:62 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcurl3-gnutls amd64 7.58.0-2ubuntu3.13 [218 kB]\n",
      "Get:63 http://archive.ubuntu.com/ubuntu bionic/main amd64 liberror-perl all 0.17025-1 [22.8 kB]\n",
      "Get:64 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 git-man all 1:2.17.1-1ubuntu0.8 [804 kB]\n",
      "Get:65 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 git amd64 1:2.17.1-1ubuntu0.8 [3916 kB]\n",
      "Get:66 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libfreetype6 amd64 2.8.1-2ubuntu2.1 [335 kB]\n",
      "Get:67 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfontconfig1 amd64 2.12.6-0ubuntu2 [137 kB]\n",
      "Get:68 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjpeg8 amd64 8c-2ubuntu8 [2194 B]\n",
      "Get:69 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig0 amd64 2.1-3.1build1 [26.7 kB]\n",
      "Get:70 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtiff5 amd64 4.0.9-5ubuntu0.4 [153 kB]\n",
      "Get:71 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwebp6 amd64 0.6.1-2 [185 kB]\n",
      "Get:72 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxpm4 amd64 1:3.5.12-1 [34.0 kB]\n",
      "Get:73 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgd3 amd64 2.2.5-4ubuntu0.4 [119 kB]\n",
      "Get:74 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 nginx-common all 1.14.0-0ubuntu1.7 [37.4 kB]\n",
      "Get:75 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libnginx-mod-http-geoip amd64 1.14.0-0ubuntu1.7 [11.2 kB]\n",
      "Get:76 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libnginx-mod-http-image-filter amd64 1.14.0-0ubuntu1.7 [14.6 kB]\n",
      "Get:77 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxslt1.1 amd64 1.1.29-5ubuntu0.2 [150 kB]\n",
      "Get:78 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libnginx-mod-http-xslt-filter amd64 1.14.0-0ubuntu1.7 [13.0 kB]\n",
      "Get:79 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libnginx-mod-mail amd64 1.14.0-0ubuntu1.7 [41.8 kB]\n",
      "Get:80 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libnginx-mod-stream amd64 1.14.0-0ubuntu1.7 [63.7 kB]\n",
      "Get:81 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 nginx-core amd64 1.14.0-0ubuntu1.7 [413 kB]\n",
      "Get:82 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 nginx all 1.14.0-0ubuntu1.7 [3596 B]\n",
      "Get:83 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.4 [1653 kB]\n",
      "Get:84 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-lib2to3 all 3.6.9-1~18.04 [77.4 kB]\n",
      "Get:85 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-distutils all 3.6.9-1~18.04 [144 kB]\n",
      "Get:86 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-pip all 9.0.1-2.3~ubuntu1.18.04.4 [114 kB]\n",
      "Get:87 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
      "Get:88 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-setuptools all 39.0.1-2 [248 kB]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 36.5 MB in 8s (4492 kB/s)\n",
      "Selecting previously unselected package libssl1.1:amd64.\r\n",
      "(Reading database ... \r",
      "(Reading database ... 5%\r",
      "(Reading database ... 10%\r",
      "(Reading database ... 15%\r",
      "(Reading database ... 20%\r",
      "(Reading database ... 25%\r",
      "(Reading database ... 30%\r",
      "(Reading database ... 35%\r",
      "(Reading database ... 40%\r",
      "(Reading database ... 45%\r",
      "(Reading database ... 50%\r",
      "(Reading database ... 55%\r",
      "(Reading database ... 60%\r",
      "(Reading database ... 65%\r",
      "(Reading database ... 70%\r",
      "(Reading database ... 75%\r",
      "(Reading database ... 80%\r",
      "(Reading database ... 85%\r",
      "(Reading database ... 90%\r",
      "(Reading database ... 95%\r",
      "(Reading database ... 100%\r",
      "(Reading database ... 4045 files and directories currently installed.)\r\n",
      "Preparing to unpack .../libssl1.1_1.1.1-1ubuntu2.1~18.04.9_amd64.deb ...\r\n",
      "Unpacking libssl1.1:amd64 (1.1.1-1ubuntu2.1~18.04.9) ...\r\n",
      "Selecting previously unselected package libpython3.6-minimal:amd64.\r\n",
      "Preparing to unpack .../libpython3.6-minimal_3.6.9-1~18.04ubuntu1.4_amd64.deb ...\r\n",
      "Unpacking libpython3.6-minimal:amd64 (3.6.9-1~18.04ubuntu1.4) ...\r\n",
      "Selecting previously unselected package libexpat1:amd64.\r\n",
      "Preparing to unpack .../libexpat1_2.2.5-3ubuntu0.2_amd64.deb ...\r\n",
      "Unpacking libexpat1:amd64 (2.2.5-3ubuntu0.2) ...\r\n",
      "Selecting previously unselected package python3.6-minimal.\r\n",
      "Preparing to unpack .../python3.6-minimal_3.6.9-1~18.04ubuntu1.4_amd64.deb ...\r\n",
      "Unpacking python3.6-minimal (3.6.9-1~18.04ubuntu1.4) ...\r\n",
      "Setting up libssl1.1:amd64 (1.1.1-1ubuntu2.1~18.04.9) ...\r\n",
      "debconf: unable to initialize frontend: Dialog\r\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\r\n",
      "debconf: falling back to frontend: Readline\r\n",
      "debconf: unable to initialize frontend: Readline\r\n",
      "debconf: (Can't locate Term/ReadLine.pm in @INC (you may need to install the Term::ReadLine module) (@INC contains: /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.26.1 /usr/local/share/perl/5.26.1 /usr/lib/x86_64-linux-gnu/perl5/5.26 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl/5.26 /usr/share/perl/5.26 /usr/local/lib/site_perl /usr/lib/x86_64-linux-gnu/perl-base) at /usr/share/perl5/Debconf/FrontEnd/Readline.pm line 7.)\r\n",
      "debconf: falling back to frontend: Teletype\r\n",
      "Setting up libpython3.6-minimal:amd64 (3.6.9-1~18.04ubuntu1.4) ...\r\n",
      "Setting up libexpat1:amd64 (2.2.5-3ubuntu0.2) ...\r\n",
      "Setting up python3.6-minimal (3.6.9-1~18.04ubuntu1.4) ...\r\n",
      "Selecting previously unselected package python3-minimal.\r\n",
      "(Reading database ... \r",
      "(Reading database ... 5%\r",
      "(Reading database ... 10%\r",
      "(Reading database ... 15%\r",
      "(Reading database ... 20%\r",
      "(Reading database ... 25%\r",
      "(Reading database ... 30%\r",
      "(Reading database ... 35%\r",
      "(Reading database ... 40%\r",
      "(Reading database ... 45%\r",
      "(Reading database ... 50%\r",
      "(Reading database ... 55%\r",
      "(Reading database ... 60%\r",
      "(Reading database ... 65%\r",
      "(Reading database ... 70%\r",
      "(Reading database ... 75%\r",
      "(Reading database ... 80%\r",
      "(Reading database ... 85%\r",
      "(Reading database ... 90%\r",
      "(Reading database ... 95%\r",
      "(Reading database ... 100%\r",
      "(Reading database ... 4302 files and directories currently installed.)\r\n",
      "Preparing to unpack .../0-python3-minimal_3.6.7-1~18.04_amd64.deb ...\r\n",
      "Unpacking python3-minimal (3.6.7-1~18.04) ...\r\n",
      "Selecting previously unselected package mime-support.\r\n",
      "Preparing to unpack .../1-mime-support_3.60ubuntu1_all.deb ...\r\n",
      "Unpacking mime-support (3.60ubuntu1) ...\r\n",
      "Selecting previously unselected package libmpdec2:amd64.\r\n",
      "Preparing to unpack .../2-libmpdec2_2.4.2-1ubuntu1_amd64.deb ...\r\n",
      "Unpacking libmpdec2:amd64 (2.4.2-1ubuntu1) ...\r\n",
      "Selecting previously unselected package readline-common.\r\n",
      "Preparing to unpack .../3-readline-common_7.0-3_all.deb ...\r\n",
      "Unpacking readline-common (7.0-3) ...\r\n",
      "Selecting previously unselected package libreadline7:amd64.\r\n",
      "Preparing to unpack .../4-libreadline7_7.0-3_amd64.deb ...\r\n",
      "Unpacking libreadline7:amd64 (7.0-3) ...\r\n",
      "Selecting previously unselected package libsqlite3-0:amd64.\r\n",
      "Preparing to unpack .../5-libsqlite3-0_3.22.0-1ubuntu0.4_amd64.deb ...\r\n",
      "Unpacking libsqlite3-0:amd64 (3.22.0-1ubuntu0.4) ...\r\n",
      "Selecting previously unselected package libpython3.6-stdlib:amd64.\r\n",
      "Preparing to unpack .../6-libpython3.6-stdlib_3.6.9-1~18.04ubuntu1.4_amd64.deb ...\r\n",
      "Unpacking libpython3.6-stdlib:amd64 (3.6.9-1~18.04ubuntu1.4) ...\r\n",
      "Selecting previously unselected package python3.6.\r\n",
      "Preparing to unpack .../7-python3.6_3.6.9-1~18.04ubuntu1.4_amd64.deb ...\r\n",
      "Unpacking python3.6 (3.6.9-1~18.04ubuntu1.4) ...\r\n",
      "Selecting previously unselected package libpython3-stdlib:amd64.\r\n",
      "Preparing to unpack .../8-libpython3-stdlib_3.6.7-1~18.04_amd64.deb ...\r\n",
      "Unpacking libpython3-stdlib:amd64 (3.6.7-1~18.04) ...\r\n",
      "Setting up python3-minimal (3.6.7-1~18.04) ...\r\n",
      "Selecting previously unselected package python3.\r\n",
      "(Reading database ... \r",
      "(Reading database ... 5%\r",
      "(Reading database ... 10%\r",
      "(Reading database ... 15%\r",
      "(Reading database ... 20%\r",
      "(Reading database ... 25%\r",
      "(Reading database ... 30%\r",
      "(Reading database ... 35%\r",
      "(Reading database ... 40%\r",
      "(Reading database ... 45%\r",
      "(Reading database ... 50%\r",
      "(Reading database ... 55%\r",
      "(Reading database ... 60%\r",
      "(Reading database ... 65%\r",
      "(Reading database ... 70%\r",
      "(Reading database ... 75%\r",
      "(Reading database ... 80%\r",
      "(Reading database ... 85%\r",
      "(Reading database ... 90%\r",
      "(Reading database ... 95%\r",
      "(Reading database ... 100%\r",
      "(Reading database ... 4760 files and directories currently installed.)\r\n",
      "Preparing to unpack .../python3_3.6.7-1~18.04_amd64.deb ...\r\n",
      "Unpacking python3 (3.6.7-1~18.04) ...\r\n",
      "Selecting previously unselected package multiarch-support.\r\n",
      "Preparing to unpack .../multiarch-support_2.27-3ubuntu1.4_amd64.deb ...\r\n",
      "Unpacking multiarch-support (2.27-3ubuntu1.4) ...\r\n",
      "Setting up multiarch-support (2.27-3ubuntu1.4) ...\r\n",
      "Selecting previously unselected package libjpeg-turbo8:amd64.\r\n",
      "(Reading database ... \r",
      "(Reading database ... 5%\r",
      "(Reading database ... 10%\r",
      "(Reading database ... 15%\r",
      "(Reading database ... 20%\r",
      "(Reading database ... 25%\r",
      "(Reading database ... 30%\r",
      "(Reading database ... 35%\r",
      "(Reading database ... 40%\r",
      "(Reading database ... 45%\r",
      "(Reading database ... 50%\r",
      "(Reading database ... 55%\r",
      "(Reading database ... 60%\r",
      "(Reading database ... 65%\r",
      "(Reading database ... 70%\r",
      "(Reading database ... 75%\r",
      "(Reading database ... 80%\r",
      "(Reading database ... 85%\r",
      "(Reading database ... 90%\r",
      "(Reading database ... 95%\r",
      "(Reading database ... 100%\r",
      "(Reading database ... 4797 files and directories currently installed.)\r\n",
      "Preparing to unpack .../00-libjpeg-turbo8_1.5.2-0ubuntu5.18.04.4_amd64.deb ...\r\n",
      "Unpacking libjpeg-turbo8:amd64 (1.5.2-0ubuntu5.18.04.4) ...\r\n",
      "Selecting previously unselected package perl-modules-5.26.\r\n",
      "Preparing to unpack .../01-perl-modules-5.26_5.26.1-6ubuntu0.5_all.deb ...\r\n",
      "Unpacking perl-modules-5.26 (5.26.1-6ubuntu0.5) ...\r\n",
      "Selecting previously unselected package libgdbm5:amd64.\r\n",
      "Preparing to unpack .../02-libgdbm5_1.14.1-6_amd64.deb ...\r\n",
      "Unpacking libgdbm5:amd64 (1.14.1-6) ...\r\n",
      "Selecting previously unselected package libgdbm-compat4:amd64.\r\n",
      "Preparing to unpack .../03-libgdbm-compat4_1.14.1-6_amd64.deb ...\r\n",
      "Unpacking libgdbm-compat4:amd64 (1.14.1-6) ...\r\n",
      "Selecting previously unselected package libperl5.26:amd64.\r\n",
      "Preparing to unpack .../04-libperl5.26_5.26.1-6ubuntu0.5_amd64.deb ...\r\n",
      "Unpacking libperl5.26:amd64 (5.26.1-6ubuntu0.5) ...\r\n",
      "Selecting previously unselected package perl.\r\n",
      "Preparing to unpack .../05-perl_5.26.1-6ubuntu0.5_amd64.deb ...\r\n",
      "Unpacking perl (5.26.1-6ubuntu0.5) ...\r\n",
      "Selecting previously unselected package openssl.\r\n",
      "Preparing to unpack .../06-openssl_1.1.1-1ubuntu2.1~18.04.9_amd64.deb ...\r\n",
      "Unpacking openssl (1.1.1-1ubuntu2.1~18.04.9) ...\r\n",
      "Selecting previously unselected package ca-certificates.\r\n",
      "Preparing to unpack .../07-ca-certificates_20210119~18.04.1_all.deb ...\r\n",
      "Unpacking ca-certificates (20210119~18.04.1) ...\r\n",
      "Selecting previously unselected package libelf1:amd64.\r\n",
      "Preparing to unpack .../08-libelf1_0.170-0.4ubuntu0.1_amd64.deb ...\r\n",
      "Unpacking libelf1:amd64 (0.170-0.4ubuntu0.1) ...\r\n",
      "Selecting previously unselected package libmnl0:amd64.\r\n",
      "Preparing to unpack .../09-libmnl0_1.0.4-2_amd64.deb ...\r\n",
      "Unpacking libmnl0:amd64 (1.0.4-2) ...\r\n",
      "Selecting previously unselected package iproute2.\r\n",
      "Preparing to unpack .../10-iproute2_4.15.0-2ubuntu1.3_amd64.deb ...\r\n",
      "Unpacking iproute2 (4.15.0-2ubuntu1.3) ...\r\n",
      "Selecting previously unselected package libbsd0:amd64.\r\n",
      "Preparing to unpack .../11-libbsd0_0.8.7-1ubuntu0.1_amd64.deb ...\r\n",
      "Unpacking libbsd0:amd64 (0.8.7-1ubuntu0.1) ...\r\n",
      "Selecting previously unselected package libicu60:amd64.\r\n",
      "Preparing to unpack .../12-libicu60_60.2-3ubuntu3.1_amd64.deb ...\r\n",
      "Unpacking libicu60:amd64 (60.2-3ubuntu3.1) ...\r\n",
      "Selecting previously unselected package libxml2:amd64.\r\n",
      "Preparing to unpack .../13-libxml2_2.9.4+dfsg1-6.1ubuntu1.3_amd64.deb ...\r\n",
      "Unpacking libxml2:amd64 (2.9.4+dfsg1-6.1ubuntu1.3) ...\r\n",
      "Selecting previously unselected package ucf.\r\n",
      "Preparing to unpack .../14-ucf_3.0038_all.deb ...\r\n",
      "Moving old data out of the way\r\n",
      "Unpacking ucf (3.0038) ...\r\n",
      "Selecting previously unselected package libgeoip1:amd64.\r\n",
      "Preparing to unpack .../15-libgeoip1_1.6.12-1_amd64.deb ...\r\n",
      "Unpacking libgeoip1:amd64 (1.6.12-1) ...\r\n",
      "Selecting previously unselected package libkrb5support0:amd64.\r\n",
      "Preparing to unpack .../16-libkrb5support0_1.16-2ubuntu0.2_amd64.deb ...\r\n",
      "Unpacking libkrb5support0:amd64 (1.16-2ubuntu0.2) ...\r\n",
      "Selecting previously unselected package libk5crypto3:amd64.\r\n",
      "Preparing to unpack .../17-libk5crypto3_1.16-2ubuntu0.2_amd64.deb ...\r\n",
      "Unpacking libk5crypto3:amd64 (1.16-2ubuntu0.2) ...\r\n",
      "Selecting previously unselected package libkeyutils1:amd64.\r\n",
      "Preparing to unpack .../18-libkeyutils1_1.5.9-9.2ubuntu2_amd64.deb ...\r\n",
      "Unpacking libkeyutils1:amd64 (1.5.9-9.2ubuntu2) ...\r\n",
      "Selecting previously unselected package libkrb5-3:amd64.\r\n",
      "Preparing to unpack .../19-libkrb5-3_1.16-2ubuntu0.2_amd64.deb ...\r\n",
      "Unpacking libkrb5-3:amd64 (1.16-2ubuntu0.2) ...\r\n",
      "Selecting previously unselected package libgssapi-krb5-2:amd64.\r\n",
      "Preparing to unpack .../20-libgssapi-krb5-2_1.16-2ubuntu0.2_amd64.deb ...\r\n",
      "Unpacking libgssapi-krb5-2:amd64 (1.16-2ubuntu0.2) ...\r\n",
      "Selecting previously unselected package libpng16-16:amd64.\r\n",
      "Preparing to unpack .../21-libpng16-16_1.6.34-1ubuntu0.18.04.2_amd64.deb ...\r\n",
      "Unpacking libpng16-16:amd64 (1.6.34-1ubuntu0.18.04.2) ...\r\n",
      "Selecting previously unselected package libpsl5:amd64.\r\n",
      "Preparing to unpack .../22-libpsl5_0.19.1-5build1_amd64.deb ...\r\n",
      "Unpacking libpsl5:amd64 (0.19.1-5build1) ...\r\n",
      "Selecting previously unselected package libxau6:amd64.\r\n",
      "Preparing to unpack .../23-libxau6_1%3a1.0.8-1ubuntu1_amd64.deb ...\r\n",
      "Unpacking libxau6:amd64 (1:1.0.8-1ubuntu1) ...\r\n",
      "Selecting previously unselected package libxdmcp6:amd64.\r\n",
      "Preparing to unpack .../24-libxdmcp6_1%3a1.1.2-3_amd64.deb ...\r\n",
      "Unpacking libxdmcp6:amd64 (1:1.1.2-3) ...\r\n",
      "Selecting previously unselected package libxcb1:amd64.\r\n",
      "Preparing to unpack .../25-libxcb1_1.13-2~ubuntu18.04_amd64.deb ...\r\n",
      "Unpacking libxcb1:amd64 (1.13-2~ubuntu18.04) ...\r\n",
      "Selecting previously unselected package libx11-data.\r\n",
      "Preparing to unpack .../26-libx11-data_2%3a1.6.4-3ubuntu0.3_all.deb ...\r\n",
      "Unpacking libx11-data (2:1.6.4-3ubuntu0.3) ...\r\n",
      "Selecting previously unselected package libx11-6:amd64.\r\n",
      "Preparing to unpack .../27-libx11-6_2%3a1.6.4-3ubuntu0.3_amd64.deb ...\r\n",
      "Unpacking libx11-6:amd64 (2:1.6.4-3ubuntu0.3) ...\r\n",
      "Selecting previously unselected package wget.\r\n",
      "Preparing to unpack .../28-wget_1.19.4-1ubuntu2.2_amd64.deb ...\r\n",
      "Unpacking wget (1.19.4-1ubuntu2.2) ...\r\n",
      "Selecting previously unselected package fonts-dejavu-core.\r\n",
      "Preparing to unpack .../29-fonts-dejavu-core_2.37-1_all.deb ...\r\n",
      "Unpacking fonts-dejavu-core (2.37-1) ...\r\n",
      "Selecting previously unselected package fontconfig-config.\r\n",
      "Preparing to unpack .../30-fontconfig-config_2.12.6-0ubuntu2_all.deb ...\r\n",
      "Unpacking fontconfig-config (2.12.6-0ubuntu2) ...\r\n",
      "Selecting previously unselected package libroken18-heimdal:amd64.\r\n",
      "Preparing to unpack .../31-libroken18-heimdal_7.5.0+dfsg-1_amd64.deb ...\r\n",
      "Unpacking libroken18-heimdal:amd64 (7.5.0+dfsg-1) ...\r\n",
      "Selecting previously unselected package libasn1-8-heimdal:amd64.\r\n",
      "Preparing to unpack .../32-libasn1-8-heimdal_7.5.0+dfsg-1_amd64.deb ...\r\n",
      "Unpacking libasn1-8-heimdal:amd64 (7.5.0+dfsg-1) ...\r\n",
      "Selecting previously unselected package libheimbase1-heimdal:amd64.\r\n",
      "Preparing to unpack .../33-libheimbase1-heimdal_7.5.0+dfsg-1_amd64.deb ...\r\n",
      "Unpacking libheimbase1-heimdal:amd64 (7.5.0+dfsg-1) ...\r\n",
      "Selecting previously unselected package libhcrypto4-heimdal:amd64.\r\n",
      "Preparing to unpack .../34-libhcrypto4-heimdal_7.5.0+dfsg-1_amd64.deb ...\r\n",
      "Unpacking libhcrypto4-heimdal:amd64 (7.5.0+dfsg-1) ...\r\n",
      "Selecting previously unselected package libwind0-heimdal:amd64.\r\n",
      "Preparing to unpack .../35-libwind0-heimdal_7.5.0+dfsg-1_amd64.deb ...\r\n",
      "Unpacking libwind0-heimdal:amd64 (7.5.0+dfsg-1) ...\r\n",
      "Selecting previously unselected package libhx509-5-heimdal:amd64.\r\n",
      "Preparing to unpack .../36-libhx509-5-heimdal_7.5.0+dfsg-1_amd64.deb ...\r\n",
      "Unpacking libhx509-5-heimdal:amd64 (7.5.0+dfsg-1) ...\r\n",
      "Selecting previously unselected package libkrb5-26-heimdal:amd64.\r\n",
      "Preparing to unpack .../37-libkrb5-26-heimdal_7.5.0+dfsg-1_amd64.deb ...\r\n",
      "Unpacking libkrb5-26-heimdal:amd64 (7.5.0+dfsg-1) ...\r\n",
      "Selecting previously unselected package libheimntlm0-heimdal:amd64.\r\n",
      "Preparing to unpack .../38-libheimntlm0-heimdal_7.5.0+dfsg-1_amd64.deb ...\r\n",
      "Unpacking libheimntlm0-heimdal:amd64 (7.5.0+dfsg-1) ...\r\n",
      "Selecting previously unselected package libgssapi3-heimdal:amd64.\r\n",
      "Preparing to unpack .../39-libgssapi3-heimdal_7.5.0+dfsg-1_amd64.deb ...\r\n",
      "Unpacking libgssapi3-heimdal:amd64 (7.5.0+dfsg-1) ...\r\n",
      "Selecting previously unselected package libsasl2-modules-db:amd64.\r\n",
      "Preparing to unpack .../40-libsasl2-modules-db_2.1.27~101-g0780600+dfsg-3ubuntu2.3_amd64.deb ...\r\n",
      "Unpacking libsasl2-modules-db:amd64 (2.1.27~101-g0780600+dfsg-3ubuntu2.3) ...\r\n",
      "Selecting previously unselected package libsasl2-2:amd64.\r\n",
      "Preparing to unpack .../41-libsasl2-2_2.1.27~101-g0780600+dfsg-3ubuntu2.3_amd64.deb ...\r\n",
      "Unpacking libsasl2-2:amd64 (2.1.27~101-g0780600+dfsg-3ubuntu2.3) ...\r\n",
      "Selecting previously unselected package libldap-common.\r\n",
      "Preparing to unpack .../42-libldap-common_2.4.45+dfsg-1ubuntu1.10_all.deb ...\r\n",
      "Unpacking libldap-common (2.4.45+dfsg-1ubuntu1.10) ...\r\n",
      "Selecting previously unselected package libldap-2.4-2:amd64.\r\n",
      "Preparing to unpack .../43-libldap-2.4-2_2.4.45+dfsg-1ubuntu1.10_amd64.deb ...\r\n",
      "Unpacking libldap-2.4-2:amd64 (2.4.45+dfsg-1ubuntu1.10) ...\r\n",
      "Selecting previously unselected package libnghttp2-14:amd64.\r\n",
      "Preparing to unpack .../44-libnghttp2-14_1.30.0-1ubuntu1_amd64.deb ...\r\n",
      "Unpacking libnghttp2-14:amd64 (1.30.0-1ubuntu1) ...\r\n",
      "Selecting previously unselected package librtmp1:amd64.\r\n",
      "Preparing to unpack .../45-librtmp1_2.4+20151223.gitfa8646d.1-1_amd64.deb ...\r\n",
      "Unpacking librtmp1:amd64 (2.4+20151223.gitfa8646d.1-1) ...\r\n",
      "Selecting previously unselected package libcurl3-gnutls:amd64.\r\n",
      "Preparing to unpack .../46-libcurl3-gnutls_7.58.0-2ubuntu3.13_amd64.deb ...\r\n",
      "Unpacking libcurl3-gnutls:amd64 (7.58.0-2ubuntu3.13) ...\r\n",
      "Selecting previously unselected package liberror-perl.\r\n",
      "Preparing to unpack .../47-liberror-perl_0.17025-1_all.deb ...\r\n",
      "Unpacking liberror-perl (0.17025-1) ...\r\n",
      "Selecting previously unselected package git-man.\r\n",
      "Preparing to unpack .../48-git-man_1%3a2.17.1-1ubuntu0.8_all.deb ...\r\n",
      "Unpacking git-man (1:2.17.1-1ubuntu0.8) ...\r\n",
      "Selecting previously unselected package git.\r\n",
      "Preparing to unpack .../49-git_1%3a2.17.1-1ubuntu0.8_amd64.deb ...\r\n",
      "Unpacking git (1:2.17.1-1ubuntu0.8) ...\r\n",
      "Selecting previously unselected package libfreetype6:amd64.\r\n",
      "Preparing to unpack .../50-libfreetype6_2.8.1-2ubuntu2.1_amd64.deb ...\r\n",
      "Unpacking libfreetype6:amd64 (2.8.1-2ubuntu2.1) ...\r\n",
      "Selecting previously unselected package libfontconfig1:amd64.\r\n",
      "Preparing to unpack .../51-libfontconfig1_2.12.6-0ubuntu2_amd64.deb ...\r\n",
      "Unpacking libfontconfig1:amd64 (2.12.6-0ubuntu2) ...\r\n",
      "Selecting previously unselected package libjpeg8:amd64.\r\n",
      "Preparing to unpack .../52-libjpeg8_8c-2ubuntu8_amd64.deb ...\r\n",
      "Unpacking libjpeg8:amd64 (8c-2ubuntu8) ...\r\n",
      "Selecting previously unselected package libjbig0:amd64.\r\n",
      "Preparing to unpack .../53-libjbig0_2.1-3.1build1_amd64.deb ...\r\n",
      "Unpacking libjbig0:amd64 (2.1-3.1build1) ...\r\n",
      "Selecting previously unselected package libtiff5:amd64.\r\n",
      "Preparing to unpack .../54-libtiff5_4.0.9-5ubuntu0.4_amd64.deb ...\r\n",
      "Unpacking libtiff5:amd64 (4.0.9-5ubuntu0.4) ...\r\n",
      "Selecting previously unselected package libwebp6:amd64.\r\n",
      "Preparing to unpack .../55-libwebp6_0.6.1-2_amd64.deb ...\r\n",
      "Unpacking libwebp6:amd64 (0.6.1-2) ...\r\n",
      "Selecting previously unselected package libxpm4:amd64.\r\n",
      "Preparing to unpack .../56-libxpm4_1%3a3.5.12-1_amd64.deb ...\r\n",
      "Unpacking libxpm4:amd64 (1:3.5.12-1) ...\r\n",
      "Selecting previously unselected package libgd3:amd64.\r\n",
      "Preparing to unpack .../57-libgd3_2.2.5-4ubuntu0.4_amd64.deb ...\r\n",
      "Unpacking libgd3:amd64 (2.2.5-4ubuntu0.4) ...\r\n",
      "Selecting previously unselected package nginx-common.\r\n",
      "Preparing to unpack .../58-nginx-common_1.14.0-0ubuntu1.7_all.deb ...\r\n",
      "Unpacking nginx-common (1.14.0-0ubuntu1.7) ...\r\n",
      "Selecting previously unselected package libnginx-mod-http-geoip.\r\n",
      "Preparing to unpack .../59-libnginx-mod-http-geoip_1.14.0-0ubuntu1.7_amd64.deb ...\r\n",
      "Unpacking libnginx-mod-http-geoip (1.14.0-0ubuntu1.7) ...\r\n",
      "Selecting previously unselected package libnginx-mod-http-image-filter.\r\n",
      "Preparing to unpack .../60-libnginx-mod-http-image-filter_1.14.0-0ubuntu1.7_amd64.deb ...\r\n",
      "Unpacking libnginx-mod-http-image-filter (1.14.0-0ubuntu1.7) ...\r\n",
      "Selecting previously unselected package libxslt1.1:amd64.\r\n",
      "Preparing to unpack .../61-libxslt1.1_1.1.29-5ubuntu0.2_amd64.deb ...\r\n",
      "Unpacking libxslt1.1:amd64 (1.1.29-5ubuntu0.2) ...\r\n",
      "Selecting previously unselected package libnginx-mod-http-xslt-filter.\r\n",
      "Preparing to unpack .../62-libnginx-mod-http-xslt-filter_1.14.0-0ubuntu1.7_amd64.deb ...\r\n",
      "Unpacking libnginx-mod-http-xslt-filter (1.14.0-0ubuntu1.7) ...\r\n",
      "Selecting previously unselected package libnginx-mod-mail.\r\n",
      "Preparing to unpack .../63-libnginx-mod-mail_1.14.0-0ubuntu1.7_amd64.deb ...\r\n",
      "Unpacking libnginx-mod-mail (1.14.0-0ubuntu1.7) ...\r\n",
      "Selecting previously unselected package libnginx-mod-stream.\r\n",
      "Preparing to unpack .../64-libnginx-mod-stream_1.14.0-0ubuntu1.7_amd64.deb ...\r\n",
      "Unpacking libnginx-mod-stream (1.14.0-0ubuntu1.7) ...\r\n",
      "Selecting previously unselected package nginx-core.\r\n",
      "Preparing to unpack .../65-nginx-core_1.14.0-0ubuntu1.7_amd64.deb ...\r\n",
      "Unpacking nginx-core (1.14.0-0ubuntu1.7) ...\r\n",
      "Selecting previously unselected package nginx.\r\n",
      "Preparing to unpack .../66-nginx_1.14.0-0ubuntu1.7_all.deb ...\r\n",
      "Unpacking nginx (1.14.0-0ubuntu1.7) ...\r\n",
      "Selecting previously unselected package python-pip-whl.\r\n",
      "Preparing to unpack .../67-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.4_all.deb ...\r\n",
      "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.4) ...\r\n",
      "Selecting previously unselected package python3-lib2to3.\r\n",
      "Preparing to unpack .../68-python3-lib2to3_3.6.9-1~18.04_all.deb ...\r\n",
      "Unpacking python3-lib2to3 (3.6.9-1~18.04) ...\r\n",
      "Selecting previously unselected package python3-distutils.\r\n",
      "Preparing to unpack .../69-python3-distutils_3.6.9-1~18.04_all.deb ...\r\n",
      "Unpacking python3-distutils (3.6.9-1~18.04) ...\r\n",
      "Selecting previously unselected package python3-pip.\r\n",
      "Preparing to unpack .../70-python3-pip_9.0.1-2.3~ubuntu1.18.04.4_all.deb ...\r\n",
      "Unpacking python3-pip (9.0.1-2.3~ubuntu1.18.04.4) ...\r\n",
      "Selecting previously unselected package python3-pkg-resources.\r\n",
      "Preparing to unpack .../71-python3-pkg-resources_39.0.1-2_all.deb ...\r\n",
      "Unpacking python3-pkg-resources (39.0.1-2) ...\r\n",
      "Selecting previously unselected package python3-setuptools.\r\n",
      "Preparing to unpack .../72-python3-setuptools_39.0.1-2_all.deb ...\r\n",
      "Unpacking python3-setuptools (39.0.1-2) ...\r\n",
      "Setting up readline-common (7.0-3) ...\r\n",
      "Setting up git-man (1:2.17.1-1ubuntu0.8) ...\r\n",
      "Setting up libicu60:amd64 (60.2-3ubuntu3.1) ...\r\n",
      "Setting up libnghttp2-14:amd64 (1.30.0-1ubuntu1) ...\r\n",
      "Setting up mime-support (3.60ubuntu1) ...\r\n",
      "Setting up libpng16-16:amd64 (1.6.34-1ubuntu0.18.04.2) ...\r\n",
      "Setting up libjbig0:amd64 (2.1-3.1build1) ...\r\n",
      "Setting up libldap-common (2.4.45+dfsg-1ubuntu1.10) ...\r\n",
      "Setting up fonts-dejavu-core (2.37-1) ...\r\n",
      "Setting up libreadline7:amd64 (7.0-3) ...\r\n",
      "Setting up libpsl5:amd64 (0.19.1-5build1) ...\r\n",
      "Setting up libelf1:amd64 (0.170-0.4ubuntu0.1) ...\r\n",
      "Setting up nginx-common (1.14.0-0ubuntu1.7) ...\r\n",
      "debconf: unable to initialize frontend: Dialog\r\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\r\n",
      "debconf: falling back to frontend: Readline\r\n",
      "Setting up libsasl2-modules-db:amd64 (2.1.27~101-g0780600+dfsg-3ubuntu2.3) ...\r\n",
      "Setting up libsasl2-2:amd64 (2.1.27~101-g0780600+dfsg-3ubuntu2.3) ...\r\n",
      "Setting up libjpeg-turbo8:amd64 (1.5.2-0ubuntu5.18.04.4) ...\r\n",
      "Setting up libroken18-heimdal:amd64 (7.5.0+dfsg-1) ...\r\n",
      "Setting up librtmp1:amd64 (2.4+20151223.gitfa8646d.1-1) ...\r\n",
      "Setting up perl-modules-5.26 (5.26.1-6ubuntu0.5) ...\r\n",
      "Setting up libgdbm5:amd64 (1.14.1-6) ...\r\n",
      "Setting up libgeoip1:amd64 (1.6.12-1) ...\r\n",
      "Setting up libbsd0:amd64 (0.8.7-1ubuntu0.1) ...\r\n",
      "Setting up libkrb5support0:amd64 (1.16-2ubuntu0.2) ...\r\n",
      "Setting up ucf (3.0038) ...\r\n",
      "debconf: unable to initialize frontend: Dialog\r\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\r\n",
      "debconf: falling back to frontend: Readline\r\n",
      "Setting up libxml2:amd64 (2.9.4+dfsg1-6.1ubuntu1.3) ...\r\n",
      "Setting up libfreetype6:amd64 (2.8.1-2ubuntu2.1) ...\r\n",
      "Setting up libxslt1.1:amd64 (1.1.29-5ubuntu0.2) ...\r\n",
      "Setting up libheimbase1-heimdal:amd64 (7.5.0+dfsg-1) ...\r\n",
      "Setting up openssl (1.1.1-1ubuntu2.1~18.04.9) ...\r\n",
      "Setting up wget (1.19.4-1ubuntu2.2) ...\r\n",
      "Setting up libsqlite3-0:amd64 (3.22.0-1ubuntu0.4) ...\r\n",
      "Setting up libnginx-mod-mail (1.14.0-0ubuntu1.7) ...\r\n",
      "Setting up libnginx-mod-http-xslt-filter (1.14.0-0ubuntu1.7) ...\r\n",
      "Setting up libxdmcp6:amd64 (1:1.1.2-3) ...\r\n",
      "Setting up libgdbm-compat4:amd64 (1.14.1-6) ...\r\n",
      "Setting up libkeyutils1:amd64 (1.5.9-9.2ubuntu2) ...\r\n",
      "Setting up ca-certificates (20210119~18.04.1) ...\r\n",
      "debconf: unable to initialize frontend: Dialog\r\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\r\n",
      "debconf: falling back to frontend: Readline\r\n",
      "Updating certificates in /etc/ssl/certs...\r\n",
      "129 added, 0 removed; done.\r\n",
      "Setting up libmnl0:amd64 (1.0.4-2) ...\r\n",
      "Setting up libnginx-mod-http-geoip (1.14.0-0ubuntu1.7) ...\r\n",
      "Setting up libx11-data (2:1.6.4-3ubuntu0.3) ...\r\n",
      "Setting up libxau6:amd64 (1:1.0.8-1ubuntu1) ...\r\n",
      "Setting up libmpdec2:amd64 (2.4.2-1ubuntu1) ...\r\n",
      "Setting up libwebp6:amd64 (0.6.1-2) ...\r\n",
      "Setting up libjpeg8:amd64 (8c-2ubuntu8) ...\r\n",
      "Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.4) ...\r\n",
      "Setting up libpython3.6-stdlib:amd64 (3.6.9-1~18.04ubuntu1.4) ...\r\n",
      "Setting up libk5crypto3:amd64 (1.16-2ubuntu0.2) ...\r\n",
      "Setting up fontconfig-config (2.12.6-0ubuntu2) ...\r\n",
      "Setting up python3.6 (3.6.9-1~18.04ubuntu1.4) ...\r\n",
      "Setting up libnginx-mod-stream (1.14.0-0ubuntu1.7) ...\r\n",
      "Setting up libwind0-heimdal:amd64 (7.5.0+dfsg-1) ...\r\n",
      "Setting up libasn1-8-heimdal:amd64 (7.5.0+dfsg-1) ...\r\n",
      "Setting up libhcrypto4-heimdal:amd64 (7.5.0+dfsg-1) ...\r\n",
      "Setting up libtiff5:amd64 (4.0.9-5ubuntu0.4) ...\r\n",
      "Setting up iproute2 (4.15.0-2ubuntu1.3) ...\r\n",
      "Setting up libhx509-5-heimdal:amd64 (7.5.0+dfsg-1) ...\r\n",
      "Setting up libperl5.26:amd64 (5.26.1-6ubuntu0.5) ...\r\n",
      "Setting up libkrb5-3:amd64 (1.16-2ubuntu0.2) ...\r\n",
      "Setting up libkrb5-26-heimdal:amd64 (7.5.0+dfsg-1) ...\r\n",
      "Setting up libxcb1:amd64 (1.13-2~ubuntu18.04) ...\r\n",
      "Setting up libheimntlm0-heimdal:amd64 (7.5.0+dfsg-1) ...\r\n",
      "Setting up libpython3-stdlib:amd64 (3.6.7-1~18.04) ...\r\n",
      "Setting up libfontconfig1:amd64 (2.12.6-0ubuntu2) ...\r\n",
      "Setting up python3 (3.6.7-1~18.04) ...\r\n",
      "running python rtupdate hooks for python3.6...\r\n",
      "running python post-rtupdate hooks for python3.6...\r\n",
      "Setting up libx11-6:amd64 (2:1.6.4-3ubuntu0.3) ...\r\n",
      "Setting up python3-pkg-resources (39.0.1-2) ...\r\n",
      "Setting up libgssapi-krb5-2:amd64 (1.16-2ubuntu0.2) ...\r\n",
      "Setting up perl (5.26.1-6ubuntu0.5) ...\r\n",
      "Setting up libxpm4:amd64 (1:3.5.12-1) ...\r\n",
      "Setting up libgssapi3-heimdal:amd64 (7.5.0+dfsg-1) ...\r\n",
      "Setting up python3-lib2to3 (3.6.9-1~18.04) ...\r\n",
      "Setting up python3-distutils (3.6.9-1~18.04) ...\r\n",
      "Setting up liberror-perl (0.17025-1) ...\r\n",
      "Setting up libgd3:amd64 (2.2.5-4ubuntu0.4) ...\r\n",
      "Setting up libldap-2.4-2:amd64 (2.4.45+dfsg-1ubuntu1.10) ...\r\n",
      "Setting up python3-pip (9.0.1-2.3~ubuntu1.18.04.4) ...\r\n",
      "Setting up python3-setuptools (39.0.1-2) ...\r\n",
      "Setting up libcurl3-gnutls:amd64 (7.58.0-2ubuntu3.13) ...\r\n",
      "Setting up libnginx-mod-http-image-filter (1.14.0-0ubuntu1.7) ...\r\n",
      "Setting up nginx-core (1.14.0-0ubuntu1.7) ...\r\n",
      "invoke-rc.d: could not determine current runlevel\r\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\r\n",
      "Setting up git (1:2.17.1-1ubuntu0.8) ...\r\n",
      "Setting up nginx (1.14.0-0ubuntu1.7) ...\r\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.4) ...\r\n",
      "Processing triggers for ca-certificates (20210119~18.04.1) ...\r\n",
      "Updating certificates in /etc/ssl/certs...\r\n",
      "0 added, 0 removed; done.\r\n",
      "Running hooks in /etc/ca-certificates/update.d...\r\n",
      "done.\r\n",
      "Removing intermediate container 318dc59a858f\n",
      " ---> 86b4a755220e\n",
      "Step 5/13 : RUN ln -s /usr/bin/python3 /usr/bin/python\n",
      " ---> Running in d00ae1517480\n",
      "Removing intermediate container d00ae1517480\n",
      " ---> 70333265902d\n",
      "Step 6/13 : RUN ln -s /usr/bin/pip3 /usr/bin/pip\n",
      " ---> Running in 32f991709069\n",
      "Removing intermediate container 32f991709069\n",
      " ---> b5d68c3f5e21\n",
      "Step 7/13 : RUN pip install Cython --install-option=\"--no-cython-compile\"\n",
      " ---> Running in 8309e0408f7f\n",
      "Collecting Cython\n",
      "  Downloading https://files.pythonhosted.org/packages/d3/38/adc49a5aca4f644e6322237089fdcf194084f5fe41445e6e632f28b32bf7/Cython-0.29.22.tar.gz (2.1MB)\n",
      "Skipping bdist_wheel for Cython, due to binaries being disabled for it.\n",
      "Installing collected packages: Cython\n",
      "  Running setup.py install for Cython: started\n",
      "    Running setup.py install for Cython: finished with status 'done'\n",
      "Successfully installed Cython-0.29.22\n",
      "\u001b[91m/usr/lib/python3/dist-packages/pip/commands/install.py:212: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
      "  cmdoptions.check_install_build_global(options)\n",
      "\u001b[0mRemoving intermediate container 8309e0408f7f\n",
      " ---> 94bc92353ad9\n",
      "Step 8/13 : RUN pip --no-cache-dir install numpy==1.16.2 scipy==1.2.1 scikit-learn==0.20.2 pandas flask gunicorn pyarrow\n",
      " ---> Running in e135c828caae\n",
      "Collecting numpy==1.16.2\n",
      "  Downloading https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
      "Collecting scipy==1.2.1\n",
      "  Downloading https://files.pythonhosted.org/packages/7f/5f/c48860704092933bf1c4c1574a8de1ffd16bf4fde8bab190d747598844b2/scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (24.8MB)\n",
      "Collecting scikit-learn==0.20.2\n",
      "  Downloading https://files.pythonhosted.org/packages/0d/3a/b92670f5c368c20329ecc4c255993fae7934564d485c3ed7ea7b8da7f741/scikit_learn-0.20.2-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\n",
      "Collecting pandas\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/e2/00cacecafbab071c787019f00ad84ca3185952f6bb9bca9550ed83870d4d/pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5MB)\n",
      "Collecting flask\n",
      "  Downloading https://files.pythonhosted.org/packages/f2/28/2a03252dfb9ebf377f40fba6a7841b47083260bf8bd8e737b0c6952df83f/Flask-1.1.2-py2.py3-none-any.whl (94kB)\n",
      "Collecting gunicorn\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5b/0d1f0296485a6af03366604142ea8f19f0833894db3512a40ed07b2a56dd/gunicorn-20.1.0.tar.gz (370kB)\n",
      "Collecting pyarrow\n",
      "  Downloading https://files.pythonhosted.org/packages/62/d3/a482d8a4039bf931ed6388308f0cc0541d0cab46f0bbff7c897a74f1c576/pyarrow-3.0.0.tar.gz (682kB)\n",
      "Collecting pytz>=2017.2 (from pandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/70/94/784178ca5dd892a98f113cdd923372024dc04b8d40abe77ca76b5fb90ca6/pytz-2021.1-py2.py3-none-any.whl (510kB)\n",
      "Collecting python-dateutil>=2.7.3 (from pandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n",
      "Collecting Jinja2>=2.10.1 (from flask)\n",
      "  Downloading https://files.pythonhosted.org/packages/7e/c2/1eece8c95ddbc9b1aeb64f5783a9e07a286de42191b7204d67b7496ddf35/Jinja2-2.11.3-py2.py3-none-any.whl (125kB)\n",
      "Collecting Werkzeug>=0.15 (from flask)\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl (298kB)\n",
      "Collecting itsdangerous>=0.24 (from flask)\n",
      "  Downloading https://files.pythonhosted.org/packages/76/ae/44b03b253d6fade317f32c24d100b3b35c2239807046a4c953c7b89fa49e/itsdangerous-1.1.0-py2.py3-none-any.whl\n",
      "Collecting click>=5.1 (from flask)\n",
      "  Downloading https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl (82kB)\n",
      "Requirement already satisfied: setuptools>=3.0 in /usr/lib/python3/dist-packages (from gunicorn)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.7.3->pandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Collecting MarkupSafe>=0.23 (from Jinja2>=2.10.1->flask)\n",
      "  Downloading https://files.pythonhosted.org/packages/b2/5f/23e0023be6bb885d00ffbefad2942bc51a620328ee910f64abe5a8d18dd1/MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Installing collected packages: numpy, scipy, scikit-learn, pytz, six, python-dateutil, pandas, MarkupSafe, Jinja2, Werkzeug, itsdangerous, click, flask, gunicorn, pyarrow\n",
      "  Running setup.py install for gunicorn: started\n",
      "    Running setup.py install for gunicorn: finished with status 'done'\n",
      "  Running setup.py install for pyarrow: started\n",
      "    Running setup.py install for pyarrow: finished with status 'error'\n",
      "    Complete output from command /usr/bin/python3 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-jdkdj9me/pyarrow/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-6dynvj_u-record/install-record.txt --single-version-externally-managed --compile:\n",
      "    /usr/lib/python3.6/distutils/dist.py:261: UserWarning: Unknown distribution option: 'long_description_content_type'\n",
      "      warnings.warn(msg)\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.linux-x86_64-3.6\n",
      "    creating build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/orc.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/feather.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/filesystem.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/benchmark.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/cffi.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/parquet.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/fs.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/__init__.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/cuda.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/serialization.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/_generated_version.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/jvm.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/types.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/json.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/compat.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/util.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/plasma.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/dataset.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/hdfs.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/flight.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/ipc.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/csv.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/compute.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/pandas_compat.py -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    creating build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_builder.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_tensor.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_sparse_tensor.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_convert_builtin.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_memory.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_serialization_deprecated.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_strategies.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_orc.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/pandas_threaded_import.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_jvm.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/pandas_examples.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_cython.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_gandiva.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_schema.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/__init__.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_misc.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/deserialize_buffer.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_cuda_numba_interop.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_cffi.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_hdfs.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/arrow_7980.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_plasma.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_compute.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_extension_type.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_fs.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_filesystem.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_flight.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_pandas.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_deprecations.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_serialization.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/strategies.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_ipc.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_table.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_feather.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/util.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_plasma_tf_op.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_cuda.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_scalars.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_array.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_csv.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/conftest.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_json.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_adhoc_memory_leak.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_types.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_dataset.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    copying pyarrow/tests/test_io.py -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    running egg_info\n",
      "    writing pyarrow.egg-info/PKG-INFO\n",
      "    writing dependency_links to pyarrow.egg-info/dependency_links.txt\n",
      "    writing entry points to pyarrow.egg-info/entry_points.txt\n",
      "    writing requirements to pyarrow.egg-info/requires.txt\n",
      "    writing top-level names to pyarrow.egg-info/top_level.txt\n",
      "    reading manifest file 'pyarrow.egg-info/SOURCES.txt'\n",
      "    reading manifest template 'MANIFEST.in'\n",
      "    warning: no files found matching '../LICENSE.txt'\n",
      "    warning: no files found matching '../NOTICE.txt'\n",
      "    warning: no previously-included files matching '*.so' found anywhere in distribution\n",
      "    warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
      "    warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "    warning: no previously-included files matching '#*' found anywhere in distribution\n",
      "    warning: no previously-included files matching '.git*' found anywhere in distribution\n",
      "    warning: no previously-included files matching '.DS_Store' found anywhere in distribution\n",
      "    no previously-included directories found matching '.asv'\n",
      "    writing manifest file 'pyarrow.egg-info/SOURCES.txt'\n",
      "    copying pyarrow/__init__.pxd -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/_compute.pxd -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/_compute.pyx -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/_csv.pxd -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/_csv.pyx -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/_cuda.pxd -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/_cuda.pyx -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/_dataset.pyx -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/_flight.pyx -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/_fs.pxd -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/_fs.pyx -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/_hdfs.pyx -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/_json.pyx -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/_orc.pxd -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/_orc.pyx -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/_parquet.pxd -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/_parquet.pyx -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/_plasma.pyx -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/_s3fs.pyx -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/array.pxi -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/benchmark.pxi -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/builder.pxi -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/compat.pxi -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/config.pxi -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/error.pxi -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/feather.pxi -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/gandiva.pyx -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/io-hdfs.pxi -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/io.pxi -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/ipc.pxi -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/lib.pxd -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/lib.pyx -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/memory.pxi -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/pandas-shim.pxi -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/public-api.pxi -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/scalar.pxi -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/serialization.pxi -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/table.pxi -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/tensor.pxi -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    copying pyarrow/types.pxi -> build/lib.linux-x86_64-3.6/pyarrow\n",
      "    creating build/lib.linux-x86_64-3.6/pyarrow/includes\n",
      "    copying pyarrow/includes/__init__.pxd -> build/lib.linux-x86_64-3.6/pyarrow/includes\n",
      "    copying pyarrow/includes/common.pxd -> build/lib.linux-x86_64-3.6/pyarrow/includes\n",
      "    copying pyarrow/includes/libarrow.pxd -> build/lib.linux-x86_64-3.6/pyarrow/includes\n",
      "    copying pyarrow/includes/libarrow_cuda.pxd -> build/lib.linux-x86_64-3.6/pyarrow/includes\n",
      "    copying pyarrow/includes/libarrow_dataset.pxd -> build/lib.linux-x86_64-3.6/pyarrow/includes\n",
      "    copying pyarrow/includes/libarrow_flight.pxd -> build/lib.linux-x86_64-3.6/pyarrow/includes\n",
      "    copying pyarrow/includes/libarrow_fs.pxd -> build/lib.linux-x86_64-3.6/pyarrow/includes\n",
      "    copying pyarrow/includes/libgandiva.pxd -> build/lib.linux-x86_64-3.6/pyarrow/includes\n",
      "    copying pyarrow/includes/libplasma.pxd -> build/lib.linux-x86_64-3.6/pyarrow/includes\n",
      "    creating build/lib.linux-x86_64-3.6/pyarrow/tensorflow\n",
      "    copying pyarrow/tensorflow/plasma_op.cc -> build/lib.linux-x86_64-3.6/pyarrow/tensorflow\n",
      "    copying pyarrow/tests/pyarrow_cython_example.pyx -> build/lib.linux-x86_64-3.6/pyarrow/tests\n",
      "    creating build/lib.linux-x86_64-3.6/pyarrow/tests/data\n",
      "    creating build/lib.linux-x86_64-3.6/pyarrow/tests/data/feather\n",
      "    copying pyarrow/tests/data/feather/v0.17.0.version=2-compression=lz4.feather -> build/lib.linux-x86_64-3.6/pyarrow/tests/data/feather\n",
      "    creating build/lib.linux-x86_64-3.6/pyarrow/tests/data/orc\n",
      "    copying pyarrow/tests/data/orc/README.md -> build/lib.linux-x86_64-3.6/pyarrow/tests/data/orc\n",
      "    copying pyarrow/tests/data/orc/TestOrcFile.emptyFile.jsn.gz -> build/lib.linux-x86_64-3.6/pyarrow/tests/data/orc\n",
      "    copying pyarrow/tests/data/orc/TestOrcFile.emptyFile.orc -> build/lib.linux-x86_64-3.6/pyarrow/tests/data/orc\n",
      "    copying pyarrow/tests/data/orc/TestOrcFile.test1.jsn.gz -> build/lib.linux-x86_64-3.6/pyarrow/tests/data/orc\n",
      "    copying pyarrow/tests/data/orc/TestOrcFile.test1.orc -> build/lib.linux-x86_64-3.6/pyarrow/tests/data/orc\n",
      "    copying pyarrow/tests/data/orc/TestOrcFile.testDate1900.jsn.gz -> build/lib.linux-x86_64-3.6/pyarrow/tests/data/orc\n",
      "    copying pyarrow/tests/data/orc/TestOrcFile.testDate1900.orc -> build/lib.linux-x86_64-3.6/pyarrow/tests/data/orc\n",
      "    copying pyarrow/tests/data/orc/decimal.jsn.gz -> build/lib.linux-x86_64-3.6/pyarrow/tests/data/orc\n",
      "    copying pyarrow/tests/data/orc/decimal.orc -> build/lib.linux-x86_64-3.6/pyarrow/tests/data/orc\n",
      "    creating build/lib.linux-x86_64-3.6/pyarrow/tests/data/parquet\n",
      "    copying pyarrow/tests/data/parquet/v0.7.1.all-named-index.parquet -> build/lib.linux-x86_64-3.6/pyarrow/tests/data/parquet\n",
      "    copying pyarrow/tests/data/parquet/v0.7.1.column-metadata-handling.parquet -> build/lib.linux-x86_64-3.6/pyarrow/tests/data/parquet\n",
      "    copying pyarrow/tests/data/parquet/v0.7.1.parquet -> build/lib.linux-x86_64-3.6/pyarrow/tests/data/parquet\n",
      "    copying pyarrow/tests/data/parquet/v0.7.1.some-named-index.parquet -> build/lib.linux-x86_64-3.6/pyarrow/tests/data/parquet\n",
      "    creating build/lib.linux-x86_64-3.6/pyarrow/tests/parquet\n",
      "    copying pyarrow/tests/parquet/common.py -> build/lib.linux-x86_64-3.6/pyarrow/tests/parquet\n",
      "    copying pyarrow/tests/parquet/conftest.py -> build/lib.linux-x86_64-3.6/pyarrow/tests/parquet\n",
      "    copying pyarrow/tests/parquet/test_basic.py -> build/lib.linux-x86_64-3.6/pyarrow/tests/parquet\n",
      "    copying pyarrow/tests/parquet/test_data_types.py -> build/lib.linux-x86_64-3.6/pyarrow/tests/parquet\n",
      "    copying pyarrow/tests/parquet/test_dataset.py -> build/lib.linux-x86_64-3.6/pyarrow/tests/parquet\n",
      "    copying pyarrow/tests/parquet/test_datetime.py -> build/lib.linux-x86_64-3.6/pyarrow/tests/parquet\n",
      "    copying pyarrow/tests/parquet/test_metadata.py -> build/lib.linux-x86_64-3.6/pyarrow/tests/parquet\n",
      "    copying pyarrow/tests/parquet/test_pandas.py -> build/lib.linux-x86_64-3.6/pyarrow/tests/parquet\n",
      "    copying pyarrow/tests/parquet/test_parquet_file.py -> build/lib.linux-x86_64-3.6/pyarrow/tests/parquet\n",
      "    copying pyarrow/tests/parquet/test_parquet_writer.py -> build/lib.linux-x86_64-3.6/pyarrow/tests/parquet\n",
      "    running build_ext\n",
      "    creating /tmp/pip-build-jdkdj9me/pyarrow/build/temp.linux-x86_64-3.6\n",
      "    -- Running cmake for pyarrow\n",
      "    cmake -DPYTHON_EXECUTABLE=/usr/bin/python3 -DPython3_EXECUTABLE=/usr/bin/python3  -DPYARROW_BUILD_CUDA=off -DPYARROW_BUILD_FLIGHT=off -DPYARROW_BUILD_GANDIVA=off -DPYARROW_BUILD_DATASET=off -DPYARROW_BUILD_ORC=off -DPYARROW_BUILD_PARQUET=off -DPYARROW_BUILD_PLASMA=off -DPYARROW_BUILD_S3=off -DPYARROW_BUILD_HDFS=off -DPYARROW_USE_TENSORFLOW=off -DPYARROW_BUNDLE_ARROW_CPP=off -DPYARROW_BUNDLE_BOOST=off -DPYARROW_GENERATE_COVERAGE=off -DPYARROW_BOOST_USE_SHARED=on -DPYARROW_PARQUET_USE_SHARED=on -DCMAKE_BUILD_TYPE=release /tmp/pip-build-jdkdj9me/pyarrow\n",
      "    unable to execute 'cmake': No such file or directory\n",
      "    error: command 'cmake' failed with exit status 1\n",
      "    \n",
      "    ----------------------------------------\n",
      "\u001b[91mCommand \"/usr/bin/python3 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-jdkdj9me/pyarrow/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-6dynvj_u-record/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /tmp/pip-build-jdkdj9me/pyarrow/\n",
      "\u001b[0mFOLDER_DIR=sagemaker-random-forest\n",
      "533821149268.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-random-forest:latest\n",
      "The push refers to repository [533821149268.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-random-forest]\n",
      "1692a7e15303: Preparing\n",
      "a40fc8e382e4: Preparing\n",
      "d9ebc8c3b376: Preparing\n",
      "fb7d7562e220: Preparing\n",
      "4867c247f1a8: Preparing\n",
      "6f15325cc380: Preparing\n",
      "1e77dd81f9fa: Preparing\n",
      "030309cad0ba: Preparing\n",
      "6f15325cc380: Waiting\n",
      "1e77dd81f9fa: Waiting\n",
      "030309cad0ba: Waiting\n",
      "4867c247f1a8: Layer already exists\n",
      "1692a7e15303: Layer already exists\n",
      "fb7d7562e220: Layer already exists\n",
      "a40fc8e382e4: Layer already exists\n",
      "d9ebc8c3b376: Layer already exists\n",
      "030309cad0ba: Layer already exists\n",
      "6f15325cc380: Layer already exists\n",
      "1e77dd81f9fa: Layer already exists\n",
      "latest: digest: sha256:f7aef9818c8306243666cb96a0c307386abe424e68934fe3beb2339533cc14b5 size: 1989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "The command '/bin/sh -c pip --no-cache-dir install numpy==1.16.2 scipy==1.2.1 scikit-learn==0.20.2 pandas flask gunicorn pyarrow' returned a non-zero code: 1\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-random-forest # repository name\n",
    "env_param=\"FOLDER_DIR=$algorithm_name\"\n",
    "echo $env_param\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x ${algorithm_name}/train\n",
    "chmod +x ${algorithm_name}/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "#region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "echo ${fullname}\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "docker build  --build-arg ${env_param} -t ${algorithm_name} .\n",
    "\n",
    "echo ${env_param}\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "echo $fullname\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로컬 머신 (또는 SageMaker 노트북 인스턴스)에서 알고리즘 테스트 \n",
    "\n",
    "알고리즘을 처음 패키징할 때에는 여러분의 코드가 잘 동작하는지 테스트가 필요할 것입니다. `container/local_test`디렉토리에 이를 위한 프레임워크가 저장되어 있습니다. 해당 폴더에는 다음 세 가지 스크립트가 제공되며 위에 설명된 구조와 유사하게 컨테이너와 디렉토리 구조를 사용할 수 있도록 해 줍니다.\n",
    "\n",
    "* `train_local.sh`: 이미지 이름과 함께 호출하면 로컬에서 학습(training)을 실행할 수 있습니다. 예를 들어 다음과 같이 호출합니다.\n",
    "```bash\n",
    "$ ./train_local.sh sagemaker-decision-trees\n",
    "```  \n",
    "실행이 완료되면 `test_dir/model`디렉토리에 모델을 생성할 것입니다. `test_dir/input/data/...` 와 `input/config/hyperparameters.json`에는 각각 학습용 데이터와 하아퍼파라미터 설정파일이 저장되어 있습니다. 필요시 해당 내용을 수정하여 테스트합니다. (이 파일 경로는 이를 사용하는 train 파이썬코드의 내용과 매치되어야 합니다. `train_local.sh` 쉘스크립트를 직접 열어보시면 `docker run`을 통해 train 프로세스를 실행하는 간단한 코드임을 확인할 수 있습니다.)\n",
    "\n",
    "* `serve_local.sh`: 학습이 완료된 후 호스팅을 위해 로컬에서 serve를 실행하는 스크립트입니다. 로컬 학습에서 실행한 것과 마찬가지로 이미지이름을 주고 호출합니다. 예를 들어 다음과 같이 호출합니다.\n",
    "```bash\n",
    "$ ./serve_local.sh sagemaker-decision-trees\n",
    "```\n",
    "위 코드를 실행하면 8080포트를 통해 외부요청을 받을 수 있도록 컨테이너 프로세스가 구동하고 추론을 위한 `test_dir/model`에 저장된 학습된 의사결정트리 모델파일을 로드합니다. 키보드 인터럽트를 보내면 프로세스를 멈출 수 있습니다. \n",
    "\n",
    "* `predict.sh`: 예측용 입력데이터와 함께 로컬 엔드포인트로 추론 http 요청을 보냅니다. content type은 디폴트 `text/csv`를 사용합니다. 예를 들어 다음과 같이 호출합니다.\n",
    "```bash\n",
    "$ ./predict.sh payload.csv text/csv\n",
    "```\n",
    "\n",
    "본 노트북과 함께 제공된 디렉토리는 지금 다루고 있는 의사결정트리 샘플을 테스트하는 용도로 셋업된 상태입니다. local_test 디렉토리의 test_dir 폴더의 구조를 함께 참고하십시오. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Amazon SageMaker에서 커스텀 알고리즘으로 학습과 추론 실행\n",
    "\n",
    "컨테이너 패키징이 완료되면 이제 SageMaker에서도 학습과 추론을 실행할 수 있습니다. 앞서 만든 알고리즘 컨테이너를 그대로 사용합니다. \n",
    "\n",
    "## 환경 셋업\n",
    "\n",
    "SageMaker에서 사용할 S3 버킷을 설정합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, random\n",
    "string_pool = string.ascii_lowercase + string.ascii_uppercase + string.digits\n",
    "result = \"\" \n",
    "for i in range(8) : \n",
    "    result += random.choice(string_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "prefix = f'DEMO-scikit-byo-iris-{result}'\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role() # role이 s3 접근 권한 이던가? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세션 생성\n",
    "\n",
    "세션은 SageMaker 환경에 대한 접속 파리미터를 기억합니다. 이후 SageMaker 동작에 이 세션을 사용할 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습용 데이터 업로드\n",
    "\n",
    "SageMaker Python SDK에서 제공되는 도구를 이용하여 데이터를 디폴트 버킷에 업로드합니다.\n",
    "\n",
    "학습작업이 대용량 데이터를 사용하는 경우 S3 데이터 생성에 Amazon Athena, AWS Glue, or Amazon EMR와 같은 빅데이터 도구들이 함께 사용될 수 있습니다. 본 노트북은 간단히 [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) 데이터셋을 사용하며 코드와 함께 제공되었습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator 생성 및 학습 실행\n",
    "\n",
    "SageMaker를 사용하기 위해 컨테이너를 이용하여 학습할 수 있도록 Estimator를 생성합니다. 생성시 SageMaker 학습환경을 위한 설정값들을 지정합니다. \n",
    "\n",
    "* __container name__ - 이전 쉘스크립트에서 생성한 이름\n",
    "* __role__ - 학습을 실행할 IAM 역할(role)\n",
    "* __instance count__ - 학습에 사용할 머신의 개수\n",
    "* __instance type__ - 학습에 사용할 머신의 인스턴스 타입\n",
    "* __output path__ - 학습결과로 생성되는 모델 아티펙트의 저장 위치\n",
    "* __session__ - 이전 단계에서 지정한 SageMaker 세션 \n",
    "\n",
    "그 다음 S3에 업로드한 학습용 데이터를 이용하여 `fit()` 명령을 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "# 데이터 입수\n",
    "# shift_len 기준 infile\n",
    "def data_input(s3_path,file_name,test_len):\n",
    "    train_df = pd.read_parquet(s3_path+file_name,engine='pyarrow')               \n",
    "    train_df.dropna(inplace=True)\n",
    "    train_df = train_df[train_df['ITEM_CD']=='1000043']        \n",
    "    test_output = train_df[-test_len:]\n",
    "    train_output = train_df[:-test_len]\n",
    "    return train_output,test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 선택 및 원핫 인코딩\n",
    "def common_processing(df):\n",
    "    df = df.set_index('ISO_YEAR_WEEK')    \n",
    "    del df['ITEM_CD']\n",
    "    df_dtypes = df.dtypes\n",
    "    # one-hot encoding\n",
    "    to_one_hot_columns = list(df_dtypes[df_dtypes == 'object'].index)    \n",
    "    to_one_hot = df[to_one_hot_columns]\n",
    "    one_hot = pd.get_dummies(to_one_hot)\n",
    "    df.drop(columns=to_one_hot_columns, inplace=True)\n",
    "    result = pd.concat([df,one_hot],axis=1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_unique(train_df):\n",
    "    for col in train_df.columns:\n",
    "        if len(pd.unique(train_df[col]))==1:\n",
    "            del train_df[col]\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import display\n",
    "\n",
    "def match_col_train_test(train,test):\n",
    "    train_columns = train.columns\n",
    "    missing_cols = train_columns.difference(test.columns)\n",
    "    # Add a missing column in test set with default value equal to 0\n",
    "    for col in missing_cols:\n",
    "        test[col] = 0\n",
    "    # Ensure the order of column in the test set is in the same order than in train set\n",
    "    test = test[train_columns]\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_xy(df):\n",
    "    target_col =df.columns[0] \n",
    "    X = df.copy()\n",
    "    X.drop(columns=target_col, axis=1, inplace=True)\n",
    "    y = df[target_col].copy()\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WORK_DIRECTORY = 'data'\n",
    "data_location = 's3://sagemaker-studio-533821149268-00fjhlwtl4fcu/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_main(data_location):\n",
    "    test_len = 4\n",
    "    bucket = 'sagemaker-studio-533821149268-00fjhlwtl4fcu'\n",
    "    path = ''\n",
    "    bucket_path = '/'.join([bucket,path])\n",
    "    #print(bucket_path)\n",
    "    data_name = 'daesang_mart9_sales_dt.parquet'\n",
    "    s3_path = f's3://{bucket_path}'   \n",
    "    print(s3_path)\n",
    "    # Data ingestion\n",
    "    train_df,test_df = data_input(s3_path,data_name,test_len)\n",
    "    # processing1 - del col, onehot\n",
    "    train_df = common_processing(train_df)\n",
    "    test_df = common_processing(test_df)\n",
    "    # processing2 - delete_unique columns\n",
    "    train_df = delete_unique(train_df)\n",
    "    # processing3 - match columns of train \n",
    "    test_df = match_col_train_test(train_df,test_df)   \n",
    "\n",
    "    test_X, test_y = split_xy(test_df)\n",
    "    \n",
    "    train_df.to_csv(data_location+'/train/train.csv',header=None, index=False)\n",
    "    test_df.to_csv(data_location+'/test/test.csv',header=None,index=False)\n",
    "    return train_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-studio-533821149268-00fjhlwtl4fcu/data'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로컬\n",
    "# instance\n",
    "# 환경변수\n",
    "# 전처리 -> train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-studio-533821149268-00fjhlwtl4fcu/\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-67cdcd21a3cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-1b2db8ed5f8c>\u001b[0m in \u001b[0;36mpreprocessing_main\u001b[0;34m(data_location)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms3_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Data ingestion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms3_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m# processing1 - del col, onehot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_input' is not defined"
     ]
    }
   ],
   "source": [
    "train_df,test_df = preprocessing_main(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter = {'max_depth':3,'random_state':4000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/sagemaker-random-forest:latest'.format(account, region)\n",
    "\n",
    "model = sage.estimator.Estimator(role=role,\n",
    "                                instance_count=1,\n",
    "                                instance_type='ml.m4.xlarge',\n",
    "                                image_uri=image,\n",
    "                                output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "                                sagemaker_session=sess,\n",
    "                                hyperparameters=hyperparameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-06 09:03:31 Starting - Starting the training job...\n",
      "2021-04-06 09:03:54 Starting - Launching requested ML instancesProfilerReport-1617699810: InProgress\n",
      "......\n",
      "2021-04-06 09:04:55 Starting - Preparing the instances for training......\n",
      "2021-04-06 09:05:55 Downloading - Downloading input data\n",
      "2021-04-06 09:05:55 Training - Downloading the training image...\n",
      "2021-04-06 09:06:24 Uploading - Uploading generated training model\n",
      "2021-04-06 09:06:24 Failed - Training job failed\n",
      "\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mException during training: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\u001b[0m\n",
      "\u001b[34mA suitable version of pyarrow or fastparquet is required for parquet support.\u001b[0m\n",
      "\u001b[34mTrying to import the above resulted in these errors:\n",
      " - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n",
      " - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/program/train\", line 55, in train\n",
      "    raw_data.append(pd.read_parquet(file))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parquet.py\", line 316, in read_parquet\n",
      "    impl = get_engine(engine)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parquet.py\", line 32, in get_engine\n",
      "    \"Unable to find a usable engine; \"\u001b[0m\n",
      "\u001b[34mImportError: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\u001b[0m\n",
      "\u001b[34mA suitable version of pyarrow or fastparquet is required for parquet support.\u001b[0m\n",
      "\u001b[34mTrying to import the above resulted in these errors:\n",
      " - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n",
      " - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.\n",
      "\u001b[0m\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job sagemaker-random-forest-2021-04-06-09-03-30-791: Failed. Reason: AlgorithmError: Exception during training: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.\nTraceback (most recent call last):\n  File \"/opt/program/train\", line 55, in train\n    raw_data.append(pd.read_parquet(file))\n  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parquet.py\", line 316, in read_parquet\n    impl = get_engine(engine)\n  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parquet.py\", line 32, in get_engine\n    \"Unable to find a usable engine; \"\nImportError: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-b96bdade7fd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m's3://sagemaker-studio-533821149268-00fjhlwtl4fcu/raw_data/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1591\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3649\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3650\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3651\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3652\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3220\u001b[0m                 ),\n\u001b[1;32m   3221\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3222\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3223\u001b[0m             )\n\u001b[1;32m   3224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job sagemaker-random-forest-2021-04-06-09-03-30-791: Failed. Reason: AlgorithmError: Exception during training: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.\nTraceback (most recent call last):\n  File \"/opt/program/train\", line 55, in train\n    raw_data.append(pd.read_parquet(file))\n  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parquet.py\", line 316, in read_parquet\n    impl = get_engine(engine)\n  File \"/usr/local/lib/python3.6/dist-packages/pandas/io/parquet.py\", line 32, in get_engine\n    \"Unable to find a usable engine; \"\nImportError: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for"
     ]
    }
   ],
   "source": [
    "model.fit('s3://sagemaker-studio-533821149268-00fjhlwtl4fcu/raw_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-06 00:00:32 Starting - Starting the training job."
     ]
    }
   ],
   "source": [
    "#model.fit(data_location+'/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 호스팅(추론용)\n",
    "\n",
    "학습된 모델을 활용하여 HTTP 엔드포인트를 만들고 실시간 예측 서비스를 실행합니다. 다음 단계로 진행합니다.\n",
    "\n",
    "### 모델 배포(deploy)\n",
    "\n",
    "학습이 완료된 모델로부터 `deploy` 명령을 호출하면 SageMaker에 호스팅환경에 배포됩니다. 명령 실행시 인스턴스 개수와 타입을 (그리고 선택적으로 직렬화, 역직렬화 함수를) 지정합니다. \n",
    "\n",
    "%%time\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "predictor = tree.deploy(1, 'ml.m4.xlarge', serializer=CSVSerializer())\n",
    "\n",
    "### 예측 실행 \n",
    "\n",
    "학습데이터중 일부를 샘플링하여 예측용 데이터를 만들겠습니다. (학습에 사용한 데이터를 테스트용으로 사용하는 것은 바람직하지 않을 수 있지만 알고리즘 동작확인을 목적으로 진행하겠습니다.)\n",
    "\n",
    "shape = pd.read_csv(\"data/iris.csv\", header=None)\n",
    "shape.sample(3)\n",
    "\n",
    "import itertools\n",
    "\n",
    "a = [50*i for i in range(3)]\n",
    "b = [40+i for i in range(10)]\n",
    "indices = [i+j for i,j in itertools.product(a,b)]\n",
    "\n",
    "test_data = shape.iloc[indices[:-1]]\n",
    "\n",
    "`deploy()`의 결과로 리턴받은 `predictor`의 `predict()` 함수를 호출하여 예측하고자 하는 데이터에 대한 예측결과를 쉽게 얻을 수 있습니다. 직렬화함수는 데이터 컨버젼을 처리해 줍니다. \n",
    "\n",
    "print(predictor.predict(test_data.values).decode('utf-8'))\n",
    "\n",
    "### (선택) 리소스 삭제\n",
    "\n",
    "엔드포인트의 활용이 끝나면 리소스를 삭제합니다. \n",
    "\n",
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배치 추론 작업 실행 \n",
    "\n",
    "대량의 데이터에 대한 배치 추론을 위해 [Amazon SageMaker Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)을 이용할 수 있습니다. 배치작업은 입력데이터의 S3 경로와 결과를 저장할 S3 출럭폴더의 경로를 전달받습니다. 본 예제에서는 엔드포인트 호스팅과 유사하게 학습데이터셋을 이용하여 배치 추론을 진행해 보겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배치변환(Transform)작업 생성\n",
    "\n",
    "추론 작업을 실행할 컨테이너를 정의하기 위해 `Transformer`를 생성합니다. `Transformer`생성시 다음 설정을 지정해야 합니다. \n",
    "\n",
    "* __instance count__ - 추론 작업을 실행할 머신의 개수\n",
    "* __instance type__ - 추론 작업을 실행할 머신의 인스턴스 타입\n",
    "* __output path__ - 추론 결과가 저장될 위치 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_output_folder = \"batch-transform-output\"\n",
    "output_path=\"s3://sagemaker-studio-533821149268-00fjhlwtl4fcu/\"+transform_output_folder\n",
    "\n",
    "transformer = model.transformer(instance_count=1,\n",
    "                               instance_type='ml.m4.xlarge',\n",
    "                               output_path=output_path,\n",
    "                               assemble_with='Line',\n",
    "                               accept='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-studio-533821149268-00fjhlwtl4fcu/batch-transform-output'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성한 `transformer`로부터 배치 추론 씰행을 위해 `tranform()`을 호출합니다. 작업 실행시 다음 옵션들이 설정 가능합니다.\n",
    "\n",
    "* __data_location__ - 입력 데이터의 위치\n",
    "* __content_type__ - HTTP 요청을 생성할 때 사용할 콘텐츠 타입 \n",
    "* __split_type__ - 입력 데이터에 대한 구분자 \n",
    "* __input_filter__ - HTTP 요청을 생성할 때 제외되어야 할 컬럼(ID)에 대한 구분 (지정하지 않으면 전체 데이터를 사용함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformer.transform(data_location+'/test', content_type='text/csv', split_type='Line', input_filter='$[1:]') #? inputfilter\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "설정 옵션에 대한 보다 자세한 내용은 다음 [CreateTransformJob API](https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTransformJob.html) 링크를 참조하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 확인\n",
    "\n",
    "배치 추론 작업의 결과를 S3로부터 가져온 후 결과를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = sess.boto_session.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<botocore.client.S3 at 0x7f0062edc358>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-ap-northeast-2-533821149268'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform results: \n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s3_client = sess.boto_session.client('s3')\n",
    "s3_client.download_file(output_path, \"{}/iris.csv.out\".format(transform_output_folder), '/tmp/iris.csv.out')\n",
    "with open('/tmp/iris.csv.out') as f:\n",
    "    results = f.readlines()   \n",
    "print(\"Transform results: \\n{}\".format(''.join(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\r\n"
     ]
    }
   ],
   "source": [
    "! docker ps -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                                                   TAG                 IMAGE ID            CREATED             SIZE\r\n",
      "533821149268.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-decision-trees   latest              26bfbfd83383        18 hours ago        378MB\r\n",
      "sagemaker-decision-trees                                                     latest              26bfbfd83383        18 hours ago        378MB\r\n",
      "ubuntu                                                                       18.04               3339fde08fc3        6 days ago          63.3MB\r\n"
     ]
    }
   ],
   "source": [
    "! docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]0;root@21b9fb169e55: /opt/program\u0007root@21b9fb169e55:/opt/program# ^C\n",
      "\n",
      "\u001b]0;root@21b9fb169e55: /opt/program\u0007root@21b9fb169e55:/opt/program# "
     ]
    }
   ],
   "source": [
    "! docker run -it --name tmp1 sagemaker-decision-trees:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker start tmp1\n",
    "! docker attach tmp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b]0;root@4f4fb61fdc80: /opt/program\u0007root@4f4fb61fdc80:/opt/program# ^C\n",
      "\n",
      "\u001b]0;root@4f4fb61fdc80: /opt/program\u0007root@4f4fb61fdc80:/opt/program# "
     ]
    }
   ],
   "source": [
    "! docker run -it --name using_container 533821149268.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-decision-trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE                                                                        COMMAND             CREATED             STATUS                       PORTS               NAMES\r\n",
      "4f4fb61fdc80        533821149268.dkr.ecr.ap-northeast-2.amazonaws.com/sagemaker-decision-trees   \"/bin/bash\"         2 minutes ago       Exited (130) 8 seconds ago                       using_container\r\n",
      "21b9fb169e55        sagemaker-decision-trees:latest                                              \"/bin/bash\"         16 minutes ago      Exited (130) 2 minutes ago                       tmp1\r\n"
     ]
    }
   ],
   "source": [
    "! docker ps -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21b9fb169e55\r\n"
     ]
    }
   ],
   "source": [
    "! docker start 21b9fb169e55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b]0;root@21b9fb169e55: /opt/program\u0007root@21b9fb169e55:/opt/program# ^C\n",
      "\n",
      "\u001b]0;root@21b9fb169e55: /opt/program\u0007root@21b9fb169e55:/opt/program# amazon\taws  containerd  dlami\tml\n"
     ]
    }
   ],
   "source": [
    "! docker attach 21b9fb169e55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker: Error response from daemon: OCI runtime create failed: container_linux.go:370: starting container process caused: exec: \"/opt/ml\": stat /opt/ml: no such file or directory: unknown.\r\n",
      "\u001b[31mERRO\u001b[0m[0000] error waiting for container: context canceled \r\n"
     ]
    }
   ],
   "source": [
    "! docker run -it --name tmp4 sagemaker-decision-trees:latest /opt/ml && pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker run -it --name tmp1 sagemaker-decision-trees:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "usage: aws s3 cp <LocalPath> <S3Uri> or <S3Uri> <LocalPath> or <S3Uri> <S3Uri>\r\n",
      "Error: Invalid argument type\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {s3://sagemaker-ap-northeast-2-533821149268/to_exp_models/random_forest/} ~/SageMaker/sagemaker-byos-byocBYOCscikit_bring_your_own_krcontainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/sagemaker-byos-byoc/BYOC/scikit_bring_your_own_kr\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Unknown options: -R\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {'s3://sagemaker-ap-northeast-2-533821149268/to_exp_models/random_forest'} /home/ec2-user/SageMaker/sagemaker-byos-byocBYOCscikit_bring_your_own_kr/container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24\r\n",
      "-rwxrwxr-x 1 ec2-user ec2-user 1475 Mar 30 08:21 build_and_push.sh\r\n",
      "drwxrwxr-x 2 ec2-user ec2-user 4096 Apr  2 08:08 decision_trees\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 1524 Mar 30 08:21 Dockerfile\r\n",
      "drwxrwxr-x 3 ec2-user ec2-user 4096 Mar 30 08:21 local_test\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 5707 Mar 30 08:21 ReadMe.md\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l ./container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./container/random_forest’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "! mkdir ./container/random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l ./container/random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 28\r\n",
      "-rwxrwxr-x 1 ec2-user ec2-user 1475 Mar 30 08:21 build_and_push.sh\r\n",
      "drwxrwxr-x 2 ec2-user ec2-user 4096 Apr  2 08:08 decision_trees\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 1524 Mar 30 08:21 Dockerfile\r\n",
      "drwxrwxr-x 3 ec2-user ec2-user 4096 Mar 30 08:21 local_test\r\n",
      "drwxrwxr-x 2 ec2-user ec2-user 4096 Apr  2 08:56 random_forest\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 5707 Mar 30 08:21 ReadMe.md\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l ./container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! rm -r ./container/random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!aws s3 sync {'s3://sagemaker-ap-northeast-2-533821149268/to_exp_models/random_forest'} /home/ec2-user/SageMaker/sagemaker-byos-byocBYOCscikit_bring_your_own_kr/container/random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nginx.conf\n",
    "\n",
    "predictor.py\n",
    "\n",
    "serve\n",
    "\n",
    "train\n",
    "\n",
    "wsgi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive {'s3://sagemaker-ap-northeast-2-533821149268/to_exp_models/random_forest/nginx.conf'} ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-ap-northeast-2-533821149268/to_exp_models/random_forest/predictor.py to ../predictor.py\n",
      "download: s3://sagemaker-ap-northeast-2-533821149268/to_exp_models/random_forest/serve to ../serve\n",
      "download: s3://sagemaker-ap-northeast-2-533821149268/to_exp_models/random_forest/nginx.conf to ../nginx.conf\n",
      "download: s3://sagemaker-ap-northeast-2-533821149268/to_exp_models/random_forest/train to ../train\n",
      "download: s3://sagemaker-ap-northeast-2-533821149268/to_exp_models/random_forest/wsgi.py to ../wsgi.py\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync {'s3://sagemaker-ap-northeast-2-533821149268/to_exp_models/random_forest'} /home/ec2-user/SageMaker/sagemaker-byos-byoc/BYOC/scikit_bring_your_own_kr/container/random_forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync {'s3://sagemaker-ap-northeast-2-533821149268/to_exp_models/'} /home/ec2-user/SageMaker/sagemaker-byos-byoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 182.0 KiB/182.0 KiB (2.1 MiB/s) with 1 file(s) remaining\r",
      "upload: ./scikit(20210406).ipynb to s3://sagemaker-ap-northeast-2-533821149268/to_exp_models/BYOC/scikit_bring_your_own_kr/scikit(20210406).ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync /home/ec2-user/SageMaker/sagemaker-byos-byoc {'s3://sagemaker-ap-northeast-2-533821149268/to_exp_models/'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/sagemaker-byos-byoc/BYOC/scikit_bring_your_own_kr\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_input(BUCKET,FILE_NAME,SHIFT_LEN):\n",
    "    train_df = pd.read_parquet(f's3://{BUCKET}/{FILE_NAME}')       \n",
    "    #train_df.columns = col_list\n",
    "    #train_df = train_df[['ISO_YEAR_WEEK','REAL_SO_BOX']]\n",
    "    #train_df.set_index('ISO_YEAR_WEEK',inplace=True)\n",
    "    test_len = 4\n",
    "    #display(train_df)\n",
    "    #train_df.info()\n",
    "    #train_df = train_df[train_df['ITEM_CD']=='1000043']    \n",
    "    train_df = train_df[train_df['ITEM_CD']=='1000043']    \n",
    "    \n",
    "    test_output = train_df[-(SHIFT_LEN+test_len):]\n",
    "    train_output = train_df[:-test_len]\n",
    "    return train_output,test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_df_shifting(train_df,STEP, SHIFT_LEN):\n",
    "#     SHIFT_LEN = SHIFT_LEN+1\n",
    "#     df_list = []\n",
    "#     df_list.append(train_df)\n",
    "#     for SHIFT_STEP in range(STEP,SHIFT_LEN):\n",
    "#         train_df_shift = pd.DataFrame(train_df['REAL_SO_BOX'].shift(SHIFT_STEP)        )\n",
    "#         train_df_shift.columns = [f'SHIFT_STEP{SHIFT_STEP}']\n",
    "#         df_list.append(train_df_shift)        \n",
    "#     result = pd.concat(df_list,axis=1)\n",
    "#     result.dropna(inplace=True)\n",
    "#     return result       \n",
    "\n",
    "# #202016 까지 사용가능함\n",
    "# train_shift = train_df_shifting(train_df,STEP,SHIFT_LEN)\n",
    "\n",
    "# test_shift = train_df_shifting(test_df,STEP,SHIFT_LEN)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
